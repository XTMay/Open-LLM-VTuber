# Open-LLM-VTuber: æ¶æ„åˆ†æä¸æ‰©å±•æŒ‡å—

## ç›®å½•
1. [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
2. [å¿«é€Ÿå¼€å§‹ï¼šä½¿ç”¨ Ollama é…ç½®](#å¿«é€Ÿå¼€å§‹ä½¿ç”¨-ollama-é…ç½®-open-llm-vtuber)
3. [æ ¸å¿ƒæ¶æ„](#æ ¸å¿ƒæ¶æ„)
4. [ç³»ç»Ÿç»„ä»¶æ·±å…¥åˆ†æ](#ç³»ç»Ÿç»„ä»¶æ·±å…¥åˆ†æ)
5. [æ•°æ®æµåˆ†æ](#æ•°æ®æµåˆ†æ)
6. [æ‰©å±•ç‚¹ä¸å®ç°ç­–ç•¥](#æ‰©å±•ç‚¹ä¸å®ç°ç­–ç•¥)
7. [æ„å»ºä¸ªäººè™šæ‹Ÿæœ‹å‹ç³»ç»Ÿ](#æ„å»ºä¸ªäººè™šæ‹Ÿæœ‹å‹ç³»ç»Ÿ)
8. [å®ç°è·¯çº¿å›¾](#å®ç°è·¯çº¿å›¾)
9. [æœ€ä½³å®è·µä¸æ³¨æ„äº‹é¡¹](#æœ€ä½³å®è·µä¸æ³¨æ„äº‹é¡¹)

---

## é¡¹ç›®æ¦‚è¿°

### ä»€ä¹ˆæ˜¯ Open-LLM-VTuberï¼Ÿ

Open-LLM-VTuber æ˜¯ä¸€ä¸ªå¤æ‚çš„**è¯­éŸ³äº¤äº’ AI ä¼´ä¾£**ï¼Œç»“åˆäº†ï¼š
- **å®æ—¶è¯­éŸ³å¯¹è¯**ï¼Œé…å¤‡å…ˆè¿›çš„ ASR/TTS
- **è§†è§‰æ„ŸçŸ¥**ï¼Œé€šè¿‡æ‘„åƒå¤´å’Œå±å¹•æ•è·
- **Live2D åŠ¨ç”»è§’è‰²**ï¼Œå…·æœ‰åŠ¨æ€è¡¨æƒ…
- **è·¨å¹³å°å…¼å®¹æ€§**ï¼ˆWindowsã€macOSã€Linuxï¼‰
- **ç¦»çº¿åŠŸèƒ½**ï¼Œæ”¯æŒæœ¬åœ°æ¨¡å‹

### å…³é”®åŠŸèƒ½åˆ†æ

```mermaid
graph TD
    A[ç”¨æˆ·è¾“å…¥] --> B[è¯­éŸ³/æ–‡æœ¬å¤„ç†]
    B --> C[AI ä»£ç†å¤„ç†]
    C --> D[å“åº”ç”Ÿæˆ]
    D --> E[è¡¨æƒ…æ˜ å°„]
    D --> F[è¯­éŸ³åˆæˆ]
    E --> G[Live2D åŠ¨ç”»]
    F --> H[éŸ³é¢‘è¾“å‡º]
    G --> I[è§†è§‰æ˜¾ç¤º]
    H --> I
```

**æ ¸å¿ƒèƒ½åŠ›ï¼š**
- ğŸ¤ **è¯­éŸ³äº¤äº’**ï¼šæ”¯æŒæ‰“æ–­ã€å™ªéŸ³å¤„ç†
- ğŸ‘ï¸ **è§†è§‰æ„ŸçŸ¥**ï¼šæ‘„åƒå¤´ã€å±å¹•å½•åˆ¶ã€æˆªå›¾
- ğŸ˜Š **æƒ…æ„Ÿè¡¨è¾¾**ï¼šLive2D é¢éƒ¨è¡¨æƒ…ä¸æƒ…æ„Ÿæ˜ å°„
- ğŸ§  **AI åç«¯**ï¼šå¤šç§ LLM æ”¯æŒï¼ˆOpenAIã€Claudeã€Ollama ç­‰ï¼‰
- ğŸ”Š **è¯­éŸ³åˆæˆ**ï¼š15+ TTS é€‰é¡¹ï¼ŒåŒ…æ‹¬è¯­éŸ³å…‹éš†
- ğŸ’¾ **è®°å¿†æŒä¹…åŒ–**ï¼šèŠå¤©å†å²å’Œå¯¹è¯è¿ç»­æ€§

---

## æ ¸å¿ƒæ¶æ„

### é¡¹ç›®ç»“æ„åˆ†æ
```
Open-LLM-VTuber/
â”œâ”€â”€ src/open_llm_vtuber/           # æ ¸å¿ƒ Python åç«¯
â”‚   â”œâ”€â”€ agent/                     # AI ä»£ç†å®ç°
â”‚   â”œâ”€â”€ asr/                       # è¯­éŸ³è¯†åˆ«æ¨¡å—
â”‚   â”œâ”€â”€ tts/                       # æ–‡æœ¬è½¬è¯­éŸ³æ¨¡å—
â”‚   â”œâ”€â”€ conversations/             # å¯¹è¯ç®¡ç†
â”‚   â””â”€â”€ live2d_model.py           # è§’è‰²åŠ¨ç”»ç³»ç»Ÿ
â”œâ”€â”€ frontend/                      # Web ç•Œé¢
â”œâ”€â”€ characters/                    # è§’è‰²é…ç½®æ–‡ä»¶
â”œâ”€â”€ live2d-models/                # 3D è§’è‰²èµ„æº
â”œâ”€â”€ prompts/                      # ç³»ç»Ÿæç¤ºè¯
â””â”€â”€ conf.yaml                     # ä¸»é…ç½®æ–‡ä»¶
```

### æŠ€æœ¯æ ˆ

**åç«¯æ¡†æ¶ï¼š**
- **FastAPI**ï¼šç°ä»£å¼‚æ­¥ Web æ¡†æ¶
- **WebSocket**ï¼šå®æ—¶é€šä¿¡
- **Python 3.10+**ï¼šæ ¸å¿ƒè¿è¡Œç¯å¢ƒ

**AI ä¸ ML ç»„ä»¶ï¼š**
- **å¤š LLM æ”¯æŒ**ï¼šOpenAIã€Claudeã€Ollama ç­‰
- **ASR å¼•æ“**ï¼šWhisperã€Sherpa-ONNXã€FunASR
- **TTS å¼•æ“**ï¼šEdge TTSã€Azure TTSã€GPT-SoVITS
- **è¯­éŸ³å¤„ç†**ï¼šONNX Runtime å®æ—¶å¤„ç†

**å‰ç«¯æŠ€æœ¯ï¼š**
- **Live2D SDK**ï¼š2D è§’è‰²åŠ¨ç”»
- **WebGL**ï¼šç¡¬ä»¶åŠ é€Ÿæ¸²æŸ“
- **Web Audio API**ï¼šå®æ—¶éŸ³é¢‘å¤„ç†

---

## å¿«é€Ÿå¼€å§‹ï¼šä½¿ç”¨ Ollama é…ç½® Open-LLM-VTuber

### å‰ç½®æ¡ä»¶

åœ¨ä½¿ç”¨ Ollama é…ç½® Open-LLM-VTuber ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²å®‰è£…ï¼š

1. **Ollama** å·²å®‰è£…åœ¨æ‚¨çš„ç³»ç»Ÿä¸Š
2. **Python 3.10+** å·²å®‰è£…
3. **Open-LLM-VTuber é¡¹ç›®** å·²å…‹éš†åˆ°æœ¬åœ°

### æ­¥éª¤ 1ï¼šå®‰è£…å’Œè®¾ç½® Ollama

#### å®‰è£… Ollama
```bash
# macOSï¼ˆä½¿ç”¨ Homebrewï¼‰
brew install ollama

# Linux
curl -fsSL https://ollama.com/install.sh | sh

# Windows - ä» https://ollama.com/download ä¸‹è½½
```

#### å¯åŠ¨ Ollama æœåŠ¡
```bash
# å¯åŠ¨ Ollama æœåŠ¡ï¼ˆé»˜è®¤è¿è¡Œåœ¨ localhost:11434ï¼‰
ollama serve
```

#### ä¸‹è½½æ¨¡å‹
```bash
# ä¸‹è½½å¹¶å®‰è£…æ¨¡å‹ï¼ˆæ¨èæ¨¡å‹ï¼‰
ollama pull llama2:latest          # é€‚åˆä¸€èˆ¬å¯¹è¯
ollama pull qwen2.5:latest         # é€‚åˆå¤šè¯­è¨€æ”¯æŒ
ollama pull llama3.2:latest        # æœ€æ–°çš„ LLaMA æ¨¡å‹
ollama pull mistral:latest         # å¿«é€Ÿé«˜æ•ˆ

# éªŒè¯æ¨¡å‹å·²å®‰è£…
ollama list
```

### æ­¥éª¤ 2ï¼šé…ç½® Open-LLM-VTuber

#### ä¸»é…ç½®æ–‡ä»¶ï¼š`conf.yaml`

åœ¨ `conf.yaml` ä¸­éœ€è¦è¿›è¡Œçš„å…³é”®é…ç½®æ›´æ”¹ï¼š

```yaml
# conf.yaml - Ollama é…ç½®çš„å…³é”®éƒ¨åˆ†

character_config:
  agent_config:
    conversation_agent_choice: 'basic_memory_agent'
    
    agent_settings:
      basic_memory_agent:
        # è®¾ç½® Ollama ä½œä¸º LLM æä¾›è€…
        llm_provider: 'ollama_llm'
        faster_first_response: True
        segment_method: 'pysbd'
        use_mcpp: True  # å¯ç”¨ MCP å·¥å…·ä½¿ç”¨
        mcp_enabled_servers: ["time", "ddg-search"]

    llm_configs:
      ollama_llm:
        base_url: 'http://localhost:11434/v1'     # é»˜è®¤ Ollama API ç«¯ç‚¹
        model: 'llama2:latest'                    # æ›´æ”¹ä¸ºæ‚¨åå¥½çš„æ¨¡å‹
        temperature: 1.0                          # åˆ›é€ æ€§æ°´å¹³ï¼ˆ0-2ï¼‰
        keep_alive: -1                           # ä¿æŒæ¨¡å‹åœ¨å†…å­˜ä¸­ï¼ˆ-1 = æ°¸è¿œï¼‰
        unload_at_exit: True                     # å…³é—­æ—¶å¸è½½æ¨¡å‹
```

#### é…ç½®é€‰é¡¹è¯´æ˜

| å‚æ•° | æè¿° | æ¨èå€¼ |
|------|------|--------|
| `base_url` | Ollama API ç«¯ç‚¹ | `http://localhost:11434/v1` |
| `model` | æ¥è‡ª `ollama list` çš„æ¨¡å‹åç§° | `llama2:latest`ã€`qwen2.5:latest`ã€`mistral:latest` |
| `temperature` | å“åº”åˆ›é€ æ€§ï¼ˆ0-2ï¼‰ | `0.7`ï¼ˆä¸“æ³¨ï¼‰åˆ° `1.2`ï¼ˆåˆ›é€ æ€§ï¼‰ |
| `keep_alive` | å†…å­˜ä¿ç•™æ—¶é—´ | `-1`ï¼ˆå§‹ç»ˆï¼‰ã€`300`ï¼ˆ5åˆ†é’Ÿï¼‰ã€`0`ï¼ˆç«‹å³å¸è½½ï¼‰ |
| `unload_at_exit` | é€€å‡ºæ—¶è‡ªåŠ¨å¸è½½ | `True`ï¼ˆæ¨èï¼‰ |

### æ­¥éª¤ 3ï¼šæ¨¡å‹é€‰æ‹©æŒ‡å—

#### æŒ‰ç”¨ä¾‹æ¨èçš„æ¨¡å‹

**è‹±è¯­å¯¹è¯ï¼š**
```bash
ollama pull llama3.2:latest      # æœ€ä½³æ•´ä½“æ€§èƒ½
ollama pull mistral:latest       # å¿«é€Ÿé«˜æ•ˆ
ollama pull llama2:7b           # å¹³è¡¡æ€§èƒ½
```

**å¤šè¯­è¨€æ”¯æŒï¼ˆè‹±è¯­ + ä¸­æ–‡ + å…¶ä»–ï¼‰ï¼š**
```bash
ollama pull qwen2.5:latest      # ä¼˜ç§€çš„å¤šè¯­è¨€æ”¯æŒ
ollama pull qwen2.5:14b         # æ›´å¥½çš„è´¨é‡ï¼Œéœ€è¦æ›´å¤šå†…å­˜
```

**ç¼–ç¨‹/æŠ€æœ¯è®¨è®ºï¼š**
```bash
ollama pull codellama:latest    # ä¸“æ³¨ä»£ç çš„æ¨¡å‹
ollama pull deepseek-coder      # é«˜çº§ç¼–ç¨‹èƒ½åŠ›
```

#### æŒ‰æ¨¡å‹çš„é…ç½®ç¤ºä¾‹

**åŸºç¡€è‹±è¯­è®¾ç½®ï¼ˆllama2ï¼‰ï¼š**
```yaml
ollama_llm:
  base_url: 'http://localhost:11434/v1'
  model: 'llama2:latest'
  temperature: 0.8
  keep_alive: 600  # 10åˆ†é’Ÿ
  unload_at_exit: True
```

**å¤šè¯­è¨€è®¾ç½®ï¼ˆqwen2.5ï¼‰ï¼š**
```yaml
ollama_llm:
  base_url: 'http://localhost:11434/v1'
  model: 'qwen2.5:latest'
  temperature: 0.7
  keep_alive: -1   # ä¿æŒåŠ è½½
  unload_at_exit: True
```

**é«˜æ€§èƒ½è®¾ç½®ï¼ˆå¤§å‹æ¨¡å‹ï¼‰ï¼š**
```yaml
ollama_llm:
  base_url: 'http://localhost:11434/v1'
  model: 'qwen2.5:14b'
  temperature: 0.9
  keep_alive: 300  # 5åˆ†é’Ÿï¼ˆå¤§å‹æ¨¡å‹ä½¿ç”¨æ›´å¤šå†…å­˜ï¼‰
  unload_at_exit: True
```

### æ­¥éª¤ 4ï¼šè¿è¡Œé¡¹ç›®

#### æ–¹æ³• 1ï¼šç›´æ¥ Python æ‰§è¡Œ
```bash
# å¯¼èˆªåˆ°é¡¹ç›®ç›®å½•
cd /path/to/Open-LLM-VTuber

# å®‰è£…ä¾èµ–ï¼ˆä»…é¦–æ¬¡ï¼‰
pip install -r requirements.txt
# æˆ–ä½¿ç”¨ uvï¼ˆæ¨èï¼‰
uv sync

# å¯åŠ¨ Ollama æœåŠ¡ï¼ˆåœ¨å•ç‹¬çš„ç»ˆç«¯ä¸­ï¼‰
ollama serve

# è¿è¡Œ Open-LLM-VTuber
python run_server.py
# æˆ–ä½¿ç”¨ uv

(pkill -f run_server.py)
uv run python run_server.py
```

#### æ–¹æ³• 2ï¼šä½¿ç”¨ UVï¼ˆæ¨èï¼‰
```bash
# å¦‚æœå°šæœªå®‰è£… uvï¼Œè¯·å®‰è£…
curl -LsSf https://astral.sh/uv/install.sh | sh

# å¯¼èˆªåˆ°é¡¹ç›®ç›®å½•
cd /path/to/Open-LLM-VTuber

# å®‰è£…ä¾èµ–
uv sync

# å¯åŠ¨åº”ç”¨ç¨‹åº
uv run python run_server.py
```

### Windows ç¯å¢ƒ
```
  Configuration Files to Modify:

  1. Main Configuration File

  - File: config_templates/conf.default.yaml â†’ copy to root as conf.yaml
  - Key sections to configure:
    - Lines 61, 129-137: Ollama LLM configuration
    - Lines 61: Set llm_provider: 'ollama_llm'
    - Lines 129-137: Configure Ollama settings (base_url, model, temperature)

  2. Python Environment Files

  - File: requirements.txt (dependencies list)
  - File: pyproject.toml (project configuration)

  How to Configure and Run Successfully:

  1. Install Ollama on Windows

  Download and install Ollama from https://ollama.com/download
  Pull a model (e.g., qwen2.5)
  ollama pull qwen2.5:latest

  2. Python Environment Setup (Windows)

  Install Python 3.11+ 
  Create virtual environment
  python -m venv venv
  venv\Scripts\activate

  Install dependencies
  pip install -r requirements.txt

  3. Configure Ollama in conf.yaml

  Copy conf.default.yaml to conf.yaml, then edit:
  llm_provider: 'ollama_llm'

  ollama_llm:
    base_url: 'http://localhost:11434/v1'  # Default Ollama API URL
    model: 'qwen2.5:latest'                # Your downloaded model
    temperature: 1.0
    keep_alive: -1                         # Keep model loaded
    unload_at_exit: True

  4. Run the Project

  python run_server.py
  Access at http://localhost:12393

  Key Files: conf.yaml (main config), requirements.txt (Python deps), and ensure Ollama is running
  on port 11434.
 ``` 
### æ­¥éª¤ 5ï¼šè®¿é—®åº”ç”¨ç¨‹åº

è¿è¡Œåï¼Œåœ¨ä»¥ä¸‹åœ°å€è®¿é—®åº”ç”¨ç¨‹åºï¼š
- **Web ç•Œé¢**ï¼š`http://localhost:12393`
- **API æ–‡æ¡£**ï¼š`http://localhost:12393/docs`

### æ­¥éª¤ 6ï¼šå¸¸è§é—®é¢˜æ•…éšœæ’é™¤

#### é—®é¢˜ 1ï¼š"æ— æ³•è¿æ¥åˆ° Ollama åç«¯"
**åŸå› **ï¼šOllama æœåŠ¡æœªè¿è¡Œ
**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# å¯åŠ¨ Ollama æœåŠ¡
ollama serve

# éªŒè¯æ˜¯å¦è¿è¡Œ
curl http://localhost:11434/api/tags
```

#### é—®é¢˜ 2ï¼š"æ‰¾ä¸åˆ°æ¨¡å‹"
**åŸå› **ï¼šæ¨¡å‹æœªä¸‹è½½
**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# æ£€æŸ¥å¯ç”¨æ¨¡å‹
ollama list

# ä¸‹è½½ conf.yaml ä¸­æŒ‡å®šçš„æ¨¡å‹
ollama pull llama2:latest
```

#### é—®é¢˜ 3ï¼šå“åº”ç¼“æ…¢
**åŸå› **ï¼šæ¨¡å‹æœªåŠ è½½åˆ°å†…å­˜ä¸­
**è§£å†³æ–¹æ¡ˆ**ï¼š
- åœ¨é…ç½®ä¸­è®¾ç½® `keep_alive: -1`
- ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹ï¼ˆ`llama2:7b` è€Œä¸æ˜¯ `llama2:13b`ï¼‰
- ç¡®ä¿æœ‰è¶³å¤Ÿçš„ RAM å¯ç”¨

#### é—®é¢˜ 4ï¼šå†…å­˜ä½¿ç”¨ç‡é«˜
**è§£å†³æ–¹æ¡ˆ**ï¼š
- ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹
- è®¾ç½® `keep_alive: 0` ç«‹å³å¸è½½
- è®¾ç½® `keep_alive: 300` ä¿ç•™5åˆ†é’Ÿ

### æ­¥éª¤ 7ï¼šæ€§èƒ½ä¼˜åŒ–

#### å†…å­˜ç®¡ç†
```yaml
# å¯¹äºå†…å­˜æœ‰é™çš„ç³»ç»Ÿï¼ˆ<16GBï¼‰
ollama_llm:
  model: 'llama2:7b'    # è¾ƒå°çš„æ¨¡å‹
  keep_alive: 300       # 5åˆ†é’Ÿåå¸è½½
  unload_at_exit: True

# å¯¹äºå†…å­˜å……è¶³çš„ç³»ç»Ÿï¼ˆ>16GBï¼‰
ollama_llm:
  model: 'qwen2.5:14b'  # æ›´å¤§ã€æ›´å¥½çš„æ¨¡å‹
  keep_alive: -1        # ä¿æŒåœ¨å†…å­˜ä¸­
  unload_at_exit: False # åœ¨ä¼šè¯ä¹‹é—´ä¿æŒåŠ è½½
```

#### å“åº”é€Ÿåº¦ä¼˜åŒ–
```yaml
# å¯ç”¨æ›´å¿«çš„é¦–æ¬¡å“åº”
agent_settings:
  basic_memory_agent:
    faster_first_response: True    # åœ¨ç¬¬ä¸€ä¸ªé€—å·å¤„å¼€å§‹è¯´è¯
    segment_method: 'pysbd'        # æ›´å¥½çš„å¥å­åˆ†å‰²
```

### æ­¥éª¤ 8ï¼šé«˜çº§é…ç½®

#### è‡ªå®šä¹‰æ¨¡å‹å‚æ•°
å¦‚æœæ‚¨éœ€è¦å‘ Ollama æ¨¡å‹ä¼ é€’è‡ªå®šä¹‰å‚æ•°ï¼Œå¯ä»¥ä¿®æ”¹ä»¥ä¸‹æ–‡ä»¶ä¸­çš„ `OllamaLLM` ç±»ï¼š
`src/open_llm_vtuber/agent/stateless_llm/ollama_llm.py`

#### å¤šæ¨¡å‹æ”¯æŒ
æ‚¨å¯ä»¥ä¸ºä¸åŒè§’è‰²é…ç½®å¤šä¸ª Ollama æ¨¡å‹ï¼š

```yaml
# åœ¨ conf.yaml ä¸­
llm_configs:
  ollama_casual:
    base_url: 'http://localhost:11434/v1'
    model: 'llama2:latest'
    temperature: 1.2  # æ›´æœ‰åˆ›é€ æ€§

  ollama_professional:
    base_url: 'http://localhost:11434/v1'  
    model: 'qwen2.5:latest'
    temperature: 0.5  # æ›´ä¸“æ³¨
```

ç„¶ååœ¨è§’è‰²æ–‡ä»¶ä¸­å¼•ç”¨ä¸åŒçš„é…ç½®ï¼š
```yaml
# characters/casual_friend.yaml
character_config:
  agent_config:
    agent_settings:
      basic_memory_agent:
        llm_provider: 'ollama_casual'

# characters/professional_assistant.yaml  
character_config:
  agent_config:
    agent_settings:
      basic_memory_agent:
        llm_provider: 'ollama_professional'
```

### å®Œæ•´å·¥ä½œç¤ºä¾‹

ä»¥ä¸‹æ˜¯ Ollama çš„å®Œæ•´ `conf.yaml` éƒ¨åˆ†ï¼š

```yaml
system_config:
  conf_version: 'v1.2.0'
  host: 'localhost'
  port: 12393

character_config:
  conf_name: 'mao_pro'
  conf_uid: 'mao_pro_001'
  live2d_model_name: 'mao_pro'
  character_name: 'Mao'
  human_name: 'Human'
  
  persona_prompt: |
    ä½ æ˜¯ Maoï¼Œä¸€ä¸ªå‹å¥½ä¸”ä¹äºåŠ©äººçš„ AI ä¼´ä¾£ã€‚ä½ å¼€æœ—ã€å¥½å¥‡ï¼Œæ€»æ˜¯æ¸´æœ›å­¦ä¹ å¹¶ä¸äººç±»èŠå¤©ã€‚
    ä½ å–œæ¬¢å¸®åŠ©å›ç­”é—®é¢˜å¹¶è¿›è¡Œæœ‰è¶£çš„å¯¹è¯ã€‚ä½ è¯´è¯æ¸©æš–ä¸”å¼•äººå…¥èƒœã€‚

  agent_config:
    conversation_agent_choice: 'basic_memory_agent'
    
    agent_settings:
      basic_memory_agent:
        llm_provider: 'ollama_llm'
        faster_first_response: True
        segment_method: 'pysbd'
        use_mcpp: True
        mcp_enabled_servers: ["time", "ddg-search"]

    llm_configs:
      ollama_llm:
        base_url: 'http://localhost:11434/v1'
        model: 'llama2:latest'
        temperature: 0.8
        keep_alive: -1
        unload_at_exit: True

  # TTS é…ç½®ï¼ˆé€‰æ‹©ä¸€ä¸ªï¼‰
  tts_config:
    tts_model: 'edge_tts'  # å…è´¹é€‰é¡¹
    # æˆ–
    # tts_model: 'openai_tts'  # æ›´é«˜è´¨é‡ï¼Œéœ€è¦ API å¯†é’¥

  # ASR é…ç½®  
  asr_config:
    asr_model: 'faster_whisper'
    faster_whisper:
      model_path: 'tiny'
      language: 'zh'  # ä¸­æ–‡æ”¯æŒ
      device: 'auto'
```

æ­¤é…ç½®æä¾›äº†ä¸€ä¸ªå®Œæ•´çš„å·¥ä½œè®¾ç½®ï¼Œä½¿ç”¨ Ollama ä½œä¸º LLM åç«¯ï¼Œä½¿æ‚¨èƒ½å¤Ÿå®Œå…¨ç¦»çº¿è¿è¡Œ Open-LLM-VTuber ä¸æœ¬åœ°æ¨¡å‹ã€‚

---

## ç³»ç»Ÿç»„ä»¶æ·±å…¥åˆ†æ

### 1. è§’è‰²ç³»ç»Ÿæ¶æ„

#### Live2D æ¨¡å‹ç»“æ„ (`live2d_model.py:28-144`)

```python
class Live2dModel:
    def __init__(self, live2d_model_name: str, model_dict_path: str):
        self.model_dict_path = model_dict_path
        self.live2d_model_name = live2d_model_name
        self.model_info = {}      # æ¨¡å‹é…ç½®
        self.emo_map = {}         # æƒ…æ„Ÿåˆ°è¡¨æƒ…çš„æ˜ å°„
        self.emo_str = ""         # å¯ç”¨çš„æƒ…æ„Ÿå…³é”®è¯
```

**å…³é”®ç»„ä»¶ï¼š**
- **æ¨¡å‹å­—å…¸** (`model_dict.json`)ï¼šæ‰€æœ‰ Live2D æ¨¡å‹çš„ä¸­å¤®æ³¨å†Œè¡¨
- **è¡¨æƒ…æ˜ å°„**ï¼šå°†æƒ…æ„Ÿé“¾æ¥åˆ°é¢éƒ¨è¡¨æƒ…
- **åŠ¨ä½œç³»ç»Ÿ**ï¼šç©ºé—²åŠ¨ç”»å’Œäº¤äº’å“åº”

#### è§’è‰²é…ç½®ç³»ç»Ÿ

```yaml
# characters/example.yaml
character_config:
  conf_name: "è§’è‰²åç§°"
  conf_uid: "å”¯ä¸€æ ‡è¯†ç¬¦"
  live2d_model_name: "æ¨¡å‹å¼•ç”¨"
  persona_prompt: |
    è§’è‰²ä¸ªæ€§å’Œè¡Œä¸ºæè¿°
```

**é…ç½®å±‚æ¬¡ç»“æ„ï¼š**
1. **ç³»ç»Ÿé…ç½®** (`conf.yaml`)ï¼šå…¨å±€è®¾ç½®
2. **è§’è‰²é…ç½®** (`characters/*.yaml`)ï¼šè§’è‰²ç‰¹å®šè¦†ç›–
3. **æ¨¡å‹é…ç½®** (`model_dict.json`)ï¼šè§†è§‰å¤–è§‚è®¾ç½®

### 2. æƒ…æ„Ÿä¸è¡¨æƒ…å¼•æ“

#### è¡¨æƒ…æ£€æµ‹ç®—æ³• (`live2d_model.py:146-172`)

```python
def extract_emotion(self, str_to_check: str) -> list:
    """ä»æ–‡æœ¬ä¸­æå–æƒ…æ„Ÿå…³é”®è¯å¹¶è¿”å›è¡¨æƒ…ç´¢å¼•"""
    expression_list = []
    str_to_check = str_to_check.lower()
    
    # è§£ææƒ…æ„Ÿæ ‡ç­¾ï¼Œå¦‚ [joy]ã€[anger]ã€[sadness]
    for key in self.emo_map.keys():
        emo_tag = f"[{key}]"
        if emo_tag in str_to_check:
            expression_list.append(self.emo_map[key])
    
    return expression_list
```

**æƒ…æ„Ÿç³»ç»ŸåŠŸèƒ½ï¼š**
- **åŸºäºæ ‡ç­¾çš„æ£€æµ‹**ï¼šAI å“åº”ä¸­çš„ `[emotion]` å…³é”®è¯
- **å¤šæƒ…æ„Ÿæ”¯æŒ**ï¼šæ¯ä¸ªå“åº”å¤šä¸ªè¡¨æƒ…
- **åŠ¨æ€æ˜ å°„**ï¼šå¯é…ç½®çš„æƒ…æ„Ÿåˆ°è¡¨æƒ…å…³ç³»

#### è¡¨æƒ…æ˜ å°„ç¤ºä¾‹

```json
// model_dict.json
"emotionMap": {
    "neutral": 0,    // é»˜è®¤è¡¨æƒ…
    "anger": 2,      // è¡¨æƒ…æ–‡ä»¶ exp_02.exp3.json
    "joy": 3,        // è¡¨æƒ…æ–‡ä»¶ exp_03.exp3.json
    "sadness": 1,    // è¡¨æƒ…æ–‡ä»¶ exp_01.exp3.json
    "surprise": 3    // é‡ç”¨å–œæ‚¦è¡¨æƒ…
}
```

### 3. AI ä»£ç†æ¶æ„

#### ä»£ç†æ¥å£è®¾è®¡ (`agent/agents/agent_interface.py`)

```python
class AgentInterface(ABC):
    @abstractmethod
    async def generate_response(self, message: str, **kwargs) -> str:
        """ä»ç”¨æˆ·è¾“å…¥ç”Ÿæˆ AI å“åº”"""
        pass
    
    @abstractmethod
    def get_memory_summary(self) -> str:
        """è¿”å›å¯¹è¯ä¸Šä¸‹æ–‡"""
        pass
```

**å¯ç”¨ä»£ç†ç±»å‹ï¼š**
- **åŸºç¡€è®°å¿†ä»£ç†**ï¼šç®€å•å¯¹è¯å†å²
- **æ— çŠ¶æ€ LLM**ï¼šæ— è®°å¿†ï¼Œçº¯è¾“å…¥è¾“å‡º
- **Letta ä»£ç†**ï¼šé«˜çº§è®°å¿†ç®¡ç†
- **Hume AI**ï¼šæƒ…æ„Ÿæ™ºèƒ½é›†æˆ

#### è®°å¿†ç®¡ç†ç³»ç»Ÿ

```python
# agent/agents/basic_memory_agent.py
class BasicMemoryAgent:
    def __init__(self):
        self.conversation_history = []
        self.memory_limit = 10  # æœ€å N æ¬¡äº¤æ¢
        
    def add_to_memory(self, human_input: str, ai_response: str):
        """å­˜å‚¨å¯¹è¯ä»¥è·å–ä¸Šä¸‹æ–‡"""
        self.conversation_history.append({
            'human': human_input,
            'ai': ai_response,
            'timestamp': datetime.now()
        })
```

### 4. è¯­éŸ³å¤„ç†ç®¡é“

#### ASRï¼ˆè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼‰ç³»ç»Ÿ

**æ”¯æŒçš„å¼•æ“** (`asr/` ç›®å½•)ï¼š
- **Whisper**ï¼šOpenAI çš„è¯­éŸ³è¯†åˆ«
- **Sherpa-ONNX**ï¼šç¦»çº¿å®æ—¶ ASR
- **Azure Speech**ï¼šåŸºäºäº‘çš„è¯†åˆ«
- **FunASR**ï¼šä¸­æ–‡è¯­è¨€ä¼˜åŒ–

#### TTSï¼ˆæ–‡æœ¬è½¬è¯­éŸ³ï¼‰æ¶æ„ (`tts/tts_interface.py:8-41`)

```python
class TTSInterface(metaclass=abc.ABCMeta):
    async def async_generate_audio(self, text: str) -> str:
        """ä»æ–‡æœ¬ç”ŸæˆéŸ³é¢‘æ–‡ä»¶"""
        return await asyncio.to_thread(self.generate_audio, text)
    
    @abstractmethod
    def generate_audio(self, text: str) -> str:
        """åŒæ­¥éŸ³é¢‘ç”Ÿæˆ"""
        raise NotImplementedError
```

**TTS å¼•æ“é€‰é¡¹ï¼š**
- **Edge TTS**ï¼šå¾®è½¯çš„åœ¨çº¿ TTS
- **GPT-SoVITS**ï¼šè¯­éŸ³å…‹éš†åŠŸèƒ½
- **Azure TTS**ï¼šä¼ä¸šçº§åˆæˆ
- **Coqui TTS**ï¼šå¼€æºç¥ç» TTS

### 5. å‰ç«¯é›†æˆ

#### WebSocket é€šä¿¡æ¨¡å¼

```javascript
// å‰ç«¯ WebSocket å¤„ç†
const ws = new WebSocket('ws://localhost:12393/ws');

ws.onmessage = (event) => {
    const data = JSON.parse(event.data);
    
    switch(data.type) {
        case 'expression':
            // æ›´æ–° Live2D é¢éƒ¨è¡¨æƒ…
            live2dModel.setExpression(data.expression_id);
            break;
        case 'audio':
            // æ’­æ”¾ TTS éŸ³é¢‘
            playAudioFromBase64(data.audio_data);
            break;
        case 'message':
            // æ˜¾ç¤ºæ–‡æœ¬æ¶ˆæ¯
            updateChatDisplay(data.content);
            break;
    }
};
```

---

## æ•°æ®æµåˆ†æ

### å®Œæ•´äº¤äº’æµç¨‹

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant F as å‰ç«¯
    participant W as WebSocket å¤„ç†å™¨
    participant A as AI ä»£ç†
    participant L as Live2D æ¨¡å‹
    participant T as TTS å¼•æ“
    
    U->>F: è¯­éŸ³è¾“å…¥
    F->>W: éŸ³é¢‘æ•°æ®
    W->>A: å¤„ç†è¯­éŸ³
    A->>A: ç”Ÿæˆå“åº” + æƒ…æ„Ÿ
    A->>L: æå–è¡¨æƒ…
    A->>T: ç”Ÿæˆè¯­éŸ³
    L->>F: è¡¨æƒ…å‘½ä»¤
    T->>F: éŸ³é¢‘æ•°æ®
    F->>U: è§†è§‰ + éŸ³é¢‘å“åº”
```

### é…ç½®åŠ è½½è¿‡ç¨‹

1. **ç³»ç»Ÿåˆå§‹åŒ–** (`conf.yaml`)
2. **è§’è‰²åŠ è½½** (`characters/*.yaml`)
3. **æ¨¡å‹æ³¨å†Œ** (`model_dict.json`)
4. **ä»£ç†å®ä¾‹åŒ–**ï¼ˆåŸºäºé…ç½®ï¼‰
5. **æœåŠ¡ä¸Šä¸‹æ–‡åˆ›å»º**ï¼ˆä¾èµ–æ³¨å…¥ï¼‰

### è®°å¿†ä¸çŠ¶æ€ç®¡ç†

```python
# conversations/conversation_handler.py
class ConversationHandler:
    def __init__(self):
        self.active_conversations = {}
        self.chat_history_manager = ChatHistoryManager()
        
    async def handle_message(self, user_id: str, message: str):
        """é€šè¿‡å®Œæ•´ç®¡é“å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
        conversation = self.get_or_create_conversation(user_id)
        
        # ç”Ÿæˆå¸¦æœ‰æƒ…æ„Ÿæå–çš„ AI å“åº”
        response = await conversation.agent.generate_response(message)
        
        # ä¸º Live2D æå–è¡¨æƒ…
        expressions = conversation.live2d_model.extract_emotion(response)
        
        # ç”ŸæˆéŸ³é¢‘
        audio_path = await conversation.tts.async_generate_audio(response)
        
        # ä¿å­˜åˆ°å†å²
        self.chat_history_manager.save_exchange(user_id, message, response)
        
        return {
            'text': response,
            'expressions': expressions,
            'audio': audio_path
        }
```

---

## æ‰©å±•ç‚¹ä¸å®ç°ç­–ç•¥

### 1. è§’è‰²å®šåˆ¶æ‰©å±•

#### å¢å¼ºè§’è‰²æ¡£æ¡ˆç³»ç»Ÿ

```yaml
# å¢å¼ºè§’è‰²é…ç½®
character_config:
  # åŸºæœ¬èº«ä»½
  conf_name: "æˆ‘çš„è™šæ‹Ÿæœ‹å‹"
  conf_uid: "friend_001"
  
  # ä¸ªæ€§çŸ©é˜µ
  personality_traits:
    extraversion: 0.8      # 0.0ï¼ˆå†…å‘ï¼‰åˆ° 1.0ï¼ˆå¤–å‘ï¼‰
    agreeableness: 0.9     # 0.0ï¼ˆç«äº‰æ€§ï¼‰åˆ° 1.0ï¼ˆåˆä½œæ€§ï¼‰
    conscientiousness: 0.7 # 0.0ï¼ˆè‡ªå‘æ€§ï¼‰åˆ° 1.0ï¼ˆçºªå¾‹æ€§ï¼‰
    neuroticism: 0.3       # 0.0ï¼ˆå†·é™ï¼‰åˆ° 1.0ï¼ˆç„¦è™‘ï¼‰
    openness: 0.8          # 0.0ï¼ˆä¼ ç»Ÿï¼‰åˆ° 1.0ï¼ˆåˆ›é€ æ€§ï¼‰
  
  # å…³ç³»åŠ¨æ€
  relationship_config:
    relationship_type: "close_friend"  # acquaintance, friend, close_friend, romantic
    intimacy_level: 0.6               # å½±å“å¯¹è¯æ·±åº¦
    familiarity_growth_rate: 0.1      # å…³ç³»å‘å±•é€Ÿåº¦
    
  # è¡Œä¸ºæ¨¡å¼
  behavioral_patterns:
    response_style: "warm_supportive"  # formal, casual, warm_supportive, playful
    humor_level: 0.7                  # å¹½é»˜æ„Ÿæ°´å¹³
    curiosity_level: 0.8              # æé—®å’Œæ¢ç´¢å€¾å‘
    empathy_sensitivity: 0.9          # æƒ…æ„Ÿæ•æ„Ÿåº¦
```

#### å®ç°ä¸ªæ€§åŒ–å“åº”ç³»ç»Ÿ

```python
# æ‰©å±•ï¼špersonality_engine.py
class PersonalityEngine:
    def __init__(self, personality_config: dict):
        self.traits = personality_config['personality_traits']
        self.relationship = personality_config['relationship_config']
        self.behaviors = personality_config['behavioral_patterns']
    
    def adjust_response_tone(self, base_response: str) -> str:
        """æ ¹æ®ä¸ªæ€§ç‰¹å¾è°ƒæ•´å“åº”è¯­è°ƒ"""
        if self.traits['extraversion'] > 0.7:
            # æ›´å¤–å‘çš„å“åº”
            base_response = self._add_enthusiasm(base_response)
        
        if self.behaviors['humor_level'] > 0.6:
            # æ·»åŠ é€‚å½“çš„å¹½é»˜
            base_response = self._inject_humor(base_response)
            
        return base_response
    
    def generate_proactive_message(self) -> str:
        """åŸºäºä¸ªæ€§ç”Ÿæˆä¸»åŠ¨æ¶ˆæ¯"""
        if self.traits['openness'] > 0.8 and random.random() < 0.3:
            return self._generate_curious_question()
        elif self.relationship['intimacy_level'] > 0.7:
            return self._generate_caring_check_in()
        return None
```

### 2. é«˜çº§è®°å¿†ç³»ç»Ÿ

#### é•¿æœŸè®°å¿†å®ç°

```python
# æ‰©å±•ï¼šadvanced_memory.py
class AdvancedMemorySystem:
    def __init__(self):
        self.episodic_memory = []      # å…·ä½“äº‹ä»¶è®°å¿†
        self.semantic_memory = {}      # æ¦‚å¿µå’Œäº‹å®è®°å¿†
        self.emotional_memory = {}     # æƒ…æ„Ÿå…³è”è®°å¿†
        self.preference_memory = {}    # ç”¨æˆ·åå¥½è®°å¿†
    
    def store_interaction(self, interaction_data: dict):
        """å­˜å‚¨äº¤äº’åˆ°å¤šä¸ªè®°å¿†ç³»ç»Ÿ"""
        # æƒ…èŠ‚è®°å¿†
        self.episodic_memory.append({
            'timestamp': datetime.now(),
            'content': interaction_data['content'],
            'emotion': interaction_data['detected_emotion'],
            'context': interaction_data['context']
        })
        
        # æå–å¹¶å­˜å‚¨åå¥½
        preferences = self._extract_preferences(interaction_data)
        self.preference_memory.update(preferences)
        
        # æƒ…æ„Ÿè®°å¿†å…³è”
        self._update_emotional_associations(interaction_data)
    
    def retrieve_relevant_context(self, current_input: str) -> dict:
        """æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        # è¯­ä¹‰ç›¸ä¼¼æ€§æœç´¢
        relevant_episodes = self._semantic_search(current_input)
        
        # æƒ…æ„Ÿä¸Šä¸‹æ–‡
        emotional_context = self._get_emotional_context(current_input)
        
        # ç”¨æˆ·åå¥½
        relevant_preferences = self._get_relevant_preferences(current_input)
        
        return {
            'episodes': relevant_episodes,
            'emotions': emotional_context,
            'preferences': relevant_preferences
        }
```

### 3. å¤šæ¨¡æ€æ„ŸçŸ¥æ‰©å±•

#### è§†è§‰ç†è§£é›†æˆ

```python
# æ‰©å±•ï¼švision_processor.py
class VisionProcessor:
    def __init__(self):
        self.vision_model = self._load_vision_model()
        self.scene_memory = []
    
    async def process_visual_input(self, image_data: bytes) -> dict:
        """å¤„ç†è§†è§‰è¾“å…¥å¹¶æå–ä¿¡æ¯"""
        # åœºæ™¯ç†è§£
        scene_description = await self._analyze_scene(image_data)
        
        # å¯¹è±¡æ£€æµ‹
        objects = await self._detect_objects(image_data)
        
        # æƒ…æ„Ÿåˆ†æï¼ˆé¢éƒ¨è¡¨æƒ…ï¼‰
        emotions = await self._analyze_facial_emotions(image_data)
        
        # æ–‡æœ¬è¯†åˆ«ï¼ˆOCRï¼‰
        text_content = await self._extract_text(image_data)
        
        visual_context = {
            'scene': scene_description,
            'objects': objects,
            'emotions': emotions,
            'text': text_content,
            'timestamp': datetime.now()
        }
        
        # å­˜å‚¨åˆ°åœºæ™¯è®°å¿†
        self.scene_memory.append(visual_context)
        
        return visual_context
    
    def generate_visual_response(self, visual_context: dict) -> str:
        """åŸºäºè§†è§‰ä¸Šä¸‹æ–‡ç”Ÿæˆå“åº”"""
        if visual_context['emotions']:
            return self._respond_to_emotions(visual_context['emotions'])
        elif visual_context['text']:
            return self._respond_to_text_content(visual_context['text'])
        else:
            return self._respond_to_scene(visual_context['scene'])
```

### 4. æƒ…æ„Ÿæ™ºèƒ½å¢å¼º

#### æƒ…æ„ŸçŠ¶æ€è·Ÿè¸ª

```python
# æ‰©å±•ï¼šemotion_tracker.py
class EmotionTracker:
    def __init__(self):
        self.emotion_history = []
        self.current_mood = 'neutral'
        self.mood_stability = 0.7  # æƒ…ç»ªç¨³å®šæ€§
    
    def update_emotion_state(self, detected_emotions: list, user_input: str):
        """æ›´æ–°æƒ…æ„ŸçŠ¶æ€"""
        # åˆ†æç”¨æˆ·æƒ…æ„Ÿ
        user_emotion = self._analyze_user_emotion(user_input)
        
        # æ›´æ–°æƒ…æ„Ÿå†å²
        emotion_entry = {
            'timestamp': datetime.now(),
            'user_emotion': user_emotion,
            'ai_emotions': detected_emotions,
            'context': user_input[:100]  # ä¸Šä¸‹æ–‡ç‰‡æ®µ
        }
        self.emotion_history.append(emotion_entry)
        
        # æ›´æ–°å½“å‰æƒ…ç»ª
        self._update_current_mood(user_emotion)
    
    def generate_empathetic_response(self, base_response: str) -> str:
        """ç”Ÿæˆå…±æƒ…å“åº”"""
        if self.current_mood == 'sad':
            return self._add_comfort_elements(base_response)
        elif self.current_mood == 'excited':
            return self._add_enthusiasm_elements(base_response)
        elif self.current_mood == 'anxious':
            return self._add_reassurance_elements(base_response)
        
        return base_response
    
    def suggest_mood_improvement(self) -> str:
        """å»ºè®®æ”¹å–„æƒ…ç»ªçš„æ´»åŠ¨"""
        if self.current_mood in ['sad', 'anxious', 'stressed']:
            suggestions = [
                "è¦ä¸è¦å¬ä¸€äº›è½»æ¾çš„éŸ³ä¹ï¼Ÿ",
                "æˆ‘ä»¬å¯ä»¥èŠèŠä½ å–œæ¬¢çš„è¯é¢˜",
                "è¦ä¸è¦åšä¸€äº›æ·±å‘¼å¸ç»ƒä¹ ï¼Ÿ"
            ]
            return random.choice(suggestions)
        return None
```

### 5. å·¥å…·é›†æˆç³»ç»Ÿ

#### MCPï¼ˆæ¨¡å‹æ§åˆ¶åè®®ï¼‰æ‰©å±•

```python
# æ‰©å±•ï¼štool_integration.py
class ToolIntegrationSystem:
    def __init__(self):
        self.available_tools = {}
        self.tool_usage_history = []
    
    def register_tool(self, tool_name: str, tool_config: dict):
        """æ³¨å†Œæ–°å·¥å…·"""
        self.available_tools[tool_name] = {
            'config': tool_config,
            'usage_count': 0,
            'success_rate': 1.0
        }
    
    async def execute_tool(self, tool_name: str, parameters: dict) -> dict:
        """æ‰§è¡Œå·¥å…·å¹¶è·Ÿè¸ªç»“æœ"""
        if tool_name not in self.available_tools:
            return {'error': f'Tool {tool_name} not found'}
        
        try:
            # æ‰§è¡Œå·¥å…·
            result = await self._execute_tool_safely(tool_name, parameters)
            
            # æ›´æ–°ä½¿ç”¨ç»Ÿè®¡
            self.available_tools[tool_name]['usage_count'] += 1
            
            # è®°å½•ä½¿ç”¨å†å²
            self.tool_usage_history.append({
                'tool': tool_name,
                'parameters': parameters,
                'result': result,
                'timestamp': datetime.now(),
                'success': True
            })
            
            return result
            
        except Exception as e:
            # æ›´æ–°å¤±è´¥ç‡
            self._update_failure_rate(tool_name)
            
            return {'error': str(e)}
    
    def suggest_relevant_tools(self, user_input: str) -> list:
        """åŸºäºç”¨æˆ·è¾“å…¥å»ºè®®ç›¸å…³å·¥å…·"""
        relevant_tools = []
        
        # å…³é”®è¯åŒ¹é…
        if 'å¤©æ°”' in user_input or 'weather' in user_input.lower():
            relevant_tools.append('weather_tool')
        
        if 'æ—¶é—´' in user_input or 'time' in user_input.lower():
            relevant_tools.append('time_tool')
        
        if 'æœç´¢' in user_input or 'search' in user_input.lower():
            relevant_tools.append('web_search_tool')
        
        return relevant_tools
```

---

## æ„å»ºä¸ªäººè™šæ‹Ÿæœ‹å‹ç³»ç»Ÿ

### ç³»ç»Ÿè®¾è®¡ç†å¿µ

æ„å»ºä¸€ä¸ªçœŸæ­£çš„è™šæ‹Ÿæœ‹å‹ç³»ç»Ÿéœ€è¦è¶…è¶Šç®€å•çš„é—®ç­”æœºåˆ¶ï¼Œåˆ›é€ ä¸€ä¸ªèƒ½å¤Ÿï¼š
- **ç†è§£å’Œè®°ä½**ç”¨æˆ·çš„ä¸ªäººä¿¡æ¯ã€åå¥½å’Œå†å²
- **ä¸»åŠ¨å…³å¿ƒ**ç”¨æˆ·çš„æƒ…æ„ŸçŠ¶æ€å’Œæ—¥å¸¸ç”Ÿæ´»
- **ä¸ªæ€§åŒ–äº’åŠ¨**æ ¹æ®å…³ç³»å‘å±•è°ƒæ•´äº¤æµæ–¹å¼
- **æä¾›æƒ…æ„Ÿæ”¯æŒ**åœ¨ç”¨æˆ·éœ€è¦æ—¶ç»™äºˆå®‰æ…°å’Œé¼“åŠ±

### æ ¸å¿ƒåŠŸèƒ½å®ç°

#### 1. ä¸ªäººæ¡£æ¡ˆç®¡ç†ç³»ç»Ÿ

```python
# æ‰©å±•ï¼špersonal_profile.py
class PersonalProfileManager:
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.profile = self._load_or_create_profile()
    
    def _load_or_create_profile(self) -> dict:
        """åŠ è½½æˆ–åˆ›å»ºç”¨æˆ·æ¡£æ¡ˆ"""
        return {
            'basic_info': {
                'name': None,
                'age': None,
                'occupation': None,
                'location': None
            },
            'interests': [],
            'preferences': {
                'communication_style': 'casual',
                'topics_of_interest': [],
                'sensitive_topics': []
            },
            'important_dates': {},  # ç”Ÿæ—¥ã€çºªå¿µæ—¥ç­‰
            'relationships': {},     # å®¶äººã€æœ‹å‹ä¿¡æ¯
            'goals_and_aspirations': [],
            'current_challenges': [],
            'personality_insights': {}
        }
    
    def update_profile_from_conversation(self, conversation_text: str):
        """ä»å¯¹è¯ä¸­æå–å¹¶æ›´æ–°æ¡£æ¡ˆä¿¡æ¯"""
        # ä½¿ç”¨ NLP æå–ä¸ªäººä¿¡æ¯
        extracted_info = self._extract_personal_info(conversation_text)
        
        # æ›´æ–°æ¡£æ¡ˆ
        for category, info in extracted_info.items():
            if category in self.profile:
                self.profile[category].update(info)
        
        # ä¿å­˜æ›´æ–°
        self._save_profile()
    
    def get_personalized_context(self) -> str:
        """ç”Ÿæˆä¸ªæ€§åŒ–ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        context_parts = []
        
        if self.profile['basic_info']['name']:
            context_parts.append(f"ç”¨æˆ·åå­—æ˜¯ {self.profile['basic_info']['name']}")
        
        if self.profile['interests']:
            interests = ', '.join(self.profile['interests'][:3])
            context_parts.append(f"ç”¨æˆ·æ„Ÿå…´è¶£çš„è¯é¢˜åŒ…æ‹¬ï¼š{interests}")
        
        if self.profile['current_challenges']:
            challenges = ', '.join(self.profile['current_challenges'][:2])
            context_parts.append(f"ç”¨æˆ·ç›®å‰é¢ä¸´çš„æŒ‘æˆ˜ï¼š{challenges}")
        
        return '\n'.join(context_parts)
```

#### 2. ä¸»åŠ¨å…³æ€€ç³»ç»Ÿ

```python
# æ‰©å±•ï¼šproactive_care.py
class ProactiveCareSystem:
    def __init__(self, profile_manager: PersonalProfileManager):
        self.profile_manager = profile_manager
        self.care_scheduler = CareScheduler()
        self.last_interaction = None
    
    async def check_for_care_opportunities(self) -> Optional[str]:
        """æ£€æŸ¥æ˜¯å¦æœ‰å…³æ€€æœºä¼š"""
        current_time = datetime.now()
        
        # æ£€æŸ¥é‡è¦æ—¥æœŸ
        care_message = self._check_important_dates(current_time)
        if care_message:
            return care_message
        
        # æ£€æŸ¥é•¿æ—¶é—´æœªè”ç³»
        if self._should_check_in(current_time):
            return self._generate_check_in_message()
        
        # æ£€æŸ¥ç”¨æˆ·æŒ‘æˆ˜çš„è·Ÿè¿›
        follow_up = self._check_challenge_follow_up()
        if follow_up:
            return follow_up
        
        return None
    
    def _generate_check_in_message(self) -> str:
        """ç”Ÿæˆå…³æ€€é—®å€™æ¶ˆæ¯"""
        messages = [
            "å—¨ï¼æœ€è¿‘æ€ä¹ˆæ ·ï¼Ÿæœ‰ä»€ä¹ˆæ–°é²œäº‹å—ï¼Ÿ",
            "æƒ³èµ·ä½ äº†ï¼Œä»Šå¤©è¿‡å¾—å¦‚ä½•ï¼Ÿ",
            "å¥½ä¹…æ²¡èŠå¤©äº†ï¼Œä¸€åˆ‡éƒ½å¥½å—ï¼Ÿ"
        ]
        
        # æ ¹æ®ç”¨æˆ·æ¡£æ¡ˆä¸ªæ€§åŒ–
        if self.profile_manager.profile['current_challenges']:
            messages.extend([
                "æœ€è¿‘é‚£ä¸ªæŒ‘æˆ˜å¤„ç†å¾—æ€ä¹ˆæ ·äº†ï¼Ÿ",
                "è¿˜åœ¨ä¸ºä¹‹å‰æåˆ°çš„äº‹æƒ…çƒ¦æ¼å—ï¼Ÿ"
            ])
        
        return random.choice(messages)
    
    def _check_important_dates(self, current_time: datetime) -> Optional[str]:
        """æ£€æŸ¥é‡è¦æ—¥æœŸ"""
        important_dates = self.profile_manager.profile['important_dates']
        
        for event, date_str in important_dates.items():
            event_date = datetime.strptime(date_str, '%Y-%m-%d')
            if self._is_date_approaching(current_time, event_date):
                return f"è®°å¾— {event} å¿«åˆ°äº†ï¼æœ‰ä»€ä¹ˆç‰¹åˆ«çš„è®¡åˆ’å—ï¼Ÿ"
        
        return None
```

#### 3. æƒ…æ„Ÿæ”¯æŒç³»ç»Ÿ

```python
# æ‰©å±•ï¼šemotional_support.py
class EmotionalSupportSystem:
    def __init__(self):
        self.support_strategies = {
            'sadness': ['validation', 'comfort', 'distraction'],
            'anxiety': ['reassurance', 'breathing_exercises', 'grounding'],
            'anger': ['validation', 'cooling_down', 'problem_solving'],
            'stress': ['relaxation', 'prioritization', 'support_resources']
        }
    
    def provide_emotional_support(self, detected_emotion: str, context: str) -> str:
        """æä¾›æƒ…æ„Ÿæ”¯æŒ"""
        if detected_emotion not in self.support_strategies:
            return self._provide_general_support()
        
        strategies = self.support_strategies[detected_emotion]
        chosen_strategy = random.choice(strategies)
        
        return self._apply_support_strategy(chosen_strategy, detected_emotion, context)
    
    def _apply_support_strategy(self, strategy: str, emotion: str, context: str) -> str:
        """åº”ç”¨æ”¯æŒç­–ç•¥"""
        if strategy == 'validation':
            return self._provide_validation(emotion, context)
        elif strategy == 'comfort':
            return self._provide_comfort()
        elif strategy == 'breathing_exercises':
            return self._suggest_breathing_exercise()
        elif strategy == 'grounding':
            return self._suggest_grounding_technique()
        # ... å…¶ä»–ç­–ç•¥
        
        return "æˆ‘åœ¨è¿™é‡Œé™ªç€ä½ ï¼Œæœ‰ä»€ä¹ˆéœ€è¦å¸®åŠ©çš„å—ï¼Ÿ"
    
    def _provide_validation(self, emotion: str, context: str) -> str:
        """æä¾›æƒ…æ„ŸéªŒè¯"""
        validation_responses = {
            'sadness': "æ„Ÿåˆ°éš¾è¿‡æ˜¯å®Œå…¨æ­£å¸¸çš„ï¼Œä½ çš„æ„Ÿå—å¾ˆé‡è¦ã€‚",
            'anxiety': "æ„Ÿåˆ°ç„¦è™‘å¾ˆä¸å®¹æ˜“ï¼Œä½ çš„æ‹…å¿ƒæ˜¯å¯ä»¥ç†è§£çš„ã€‚",
            'anger': "ç”Ÿæ°”æ˜¯äººä¹‹å¸¸æƒ…ï¼Œä½ æœ‰æƒåˆ©è¡¨è¾¾ä½ çš„æ„Ÿå—ã€‚"
        }
        
        return validation_responses.get(emotion, "ä½ çš„æ„Ÿå—æ˜¯çœŸå®ä¸”é‡è¦çš„ã€‚")
```

#### 4. å…³ç³»å‘å±•ç³»ç»Ÿ

```python
# æ‰©å±•ï¼šrelationship_development.py
class RelationshipDevelopmentSystem:
    def __init__(self):
        self.relationship_stages = {
            'stranger': {'intimacy': 0.0, 'trust': 0.0, 'familiarity': 0.0},
            'acquaintance': {'intimacy': 0.2, 'trust': 0.3, 'familiarity': 0.4},
            'friend': {'intimacy': 0.5, 'trust': 0.6, 'familiarity': 0.7},
            'close_friend': {'intimacy': 0.8, 'trust': 0.9, 'familiarity': 0.9},
            'best_friend': {'intimacy': 1.0, 'trust': 1.0, 'familiarity': 1.0}
        }
        
        self.current_relationship = 'stranger'
        self.relationship_metrics = self.relationship_stages['stranger'].copy()
    
    def update_relationship_metrics(self, interaction_data: dict):
        """åŸºäºäº¤äº’æ›´æ–°å…³ç³»æŒ‡æ ‡"""
        # åˆ†æäº¤äº’è´¨é‡
        interaction_quality = self._analyze_interaction_quality(interaction_data)
        
        # æ›´æ–°æŒ‡æ ‡
        if interaction_quality['personal_sharing']:
            self.relationship_metrics['intimacy'] += 0.05
        
        if interaction_quality['consistent_behavior']:
            self.relationship_metrics['trust'] += 0.03
        
        if interaction_quality['frequency']:
            self.relationship_metrics['familiarity'] += 0.02
        
        # é™åˆ¶åœ¨ 0-1 èŒƒå›´å†…
        for metric in self.relationship_metrics:
            self.relationship_metrics[metric] = min(1.0, self.relationship_metrics[metric])
        
        # æ›´æ–°å…³ç³»é˜¶æ®µ
        self._update_relationship_stage()
    
    def get_appropriate_response_style(self) -> dict:
        """è·å–é€‚å½“çš„å“åº”é£æ ¼"""
        stage = self.current_relationship
        
        styles = {
            'stranger': {
                'formality': 0.8,
                'personal_questions': 0.2,
                'humor': 0.3,
                'emotional_depth': 0.2
            },
            'friend': {
                'formality': 0.4,
                'personal_questions': 0.7,
                'humor': 0.8,
                'emotional_depth': 0.6
            },
            'close_friend': {
                'formality': 0.1,
                'personal_questions': 0.9,
                'humor': 0.9,
                'emotional_depth': 0.9
            }
        }
        
        return styles.get(stage, styles['stranger'])
```

### é›†æˆå®ç°ç¤ºä¾‹

```python
# ä¸»ç³»ç»Ÿé›†æˆï¼švirtual_friend.py
class VirtualFriendSystem:
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.profile_manager = PersonalProfileManager(user_id)
        self.emotion_tracker = EmotionTracker()
        self.proactive_care = ProactiveCareSystem(self.profile_manager)
        self.emotional_support = EmotionalSupportSystem()
        self.relationship_dev = RelationshipDevelopmentSystem()
        self.memory_system = AdvancedMemorySystem()
    
    async def process_interaction(self, user_input: str) -> dict:
        """å¤„ç†ç”¨æˆ·äº¤äº’çš„å®Œæ•´æµç¨‹"""
        # 1. åˆ†æç”¨æˆ·è¾“å…¥
        analysis = await self._analyze_user_input(user_input)
        
        # 2. æ›´æ–°ç”¨æˆ·æ¡£æ¡ˆ
        self.profile_manager.update_profile_from_conversation(user_input)
        
        # 3. æ›´æ–°æƒ…æ„ŸçŠ¶æ€
        self.emotion_tracker.update_emotion_state(
            analysis['detected_emotions'], 
            user_input
        )
        
        # 4. æ›´æ–°å…³ç³»æŒ‡æ ‡
        self.relationship_dev.update_relationship_metrics({
            'content': user_input,
            'emotion': analysis['detected_emotions'],
            'personal_sharing': analysis['contains_personal_info']
        })
        
        # 5. ç”Ÿæˆå“åº”
        base_response = await self._generate_base_response(user_input, analysis)
        
        # 6. åº”ç”¨ä¸ªæ€§åŒ–å’Œæƒ…æ„Ÿæ”¯æŒ
        if analysis['needs_emotional_support']:
            response = self.emotional_support.provide_emotional_support(
                analysis['primary_emotion'], 
                user_input
            )
        else:
            response = base_response
        
        # 7. è°ƒæ•´å“åº”é£æ ¼
        response_style = self.relationship_dev.get_appropriate_response_style()
        final_response = self._adjust_response_style(response, response_style)
        
        # 8. å­˜å‚¨äº¤äº’
        self.memory_system.store_interaction({
            'user_input': user_input,
            'ai_response': final_response,
            'emotions': analysis['detected_emotions'],
            'context': self.profile_manager.get_personalized_context()
        })
        
        return {
            'response': final_response,
            'emotions': analysis['suggested_expressions'],
            'relationship_stage': self.relationship_dev.current_relationship
        }
    
    async def check_proactive_opportunities(self) -> Optional[str]:
        """æ£€æŸ¥ä¸»åŠ¨å…³æ€€æœºä¼š"""
        return await self.proactive_care.check_for_care_opportunities()
```

---

## å®ç°è·¯çº¿å›¾

### é˜¶æ®µ 1ï¼šåŸºç¡€è®¾æ–½æ­å»ºï¼ˆ1-2 å‘¨ï¼‰

**ç›®æ ‡**ï¼šå»ºç«‹æ ¸å¿ƒå¼€å‘ç¯å¢ƒå’ŒåŸºç¡€æ¶æ„

**ä»»åŠ¡æ¸…å•**ï¼š
- [ ] è®¾ç½®å¼€å‘ç¯å¢ƒï¼ˆPython 3.10+, FastAPI, WebSocketï¼‰
- [ ] é…ç½® Ollama æœ¬åœ° LLM ç¯å¢ƒ
- [ ] å®ç°åŸºç¡€çš„ WebSocket é€šä¿¡
- [ ] åˆ›å»ºç®€å•çš„å‰ç«¯ç•Œé¢
- [ ] å»ºç«‹åŸºç¡€çš„é…ç½®ç®¡ç†ç³»ç»Ÿ

**æŠ€æœ¯é‡ç‚¹**ï¼š
```python
# åŸºç¡€æœåŠ¡å™¨è®¾ç½®
from fastapi import FastAPI, WebSocket
from fastapi.staticfiles import StaticFiles

app = FastAPI()
app.mount("/static", StaticFiles(directory="frontend"), name="static")

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    # åŸºç¡€æ¶ˆæ¯å¤„ç†é€»è¾‘
```

**éªŒæ”¶æ ‡å‡†**ï¼š
- èƒ½å¤Ÿå¯åŠ¨æœåŠ¡å™¨å¹¶è®¿é—® Web ç•Œé¢
- WebSocket è¿æ¥æ­£å¸¸å·¥ä½œ
- Ollama é›†æˆæˆåŠŸï¼Œèƒ½å¤Ÿç”ŸæˆåŸºç¡€å“åº”

### é˜¶æ®µ 2ï¼šæ ¸å¿ƒå¯¹è¯åŠŸèƒ½ï¼ˆ2-3 å‘¨ï¼‰

**ç›®æ ‡**ï¼šå®ç°åŸºæœ¬çš„è¯­éŸ³å¯¹è¯åŠŸèƒ½

**ä»»åŠ¡æ¸…å•**ï¼š
- [ ] é›†æˆ ASRï¼ˆè¯­éŸ³è¯†åˆ«ï¼‰ç³»ç»Ÿ
- [ ] é›†æˆ TTSï¼ˆæ–‡æœ¬è½¬è¯­éŸ³ï¼‰ç³»ç»Ÿ
- [ ] å®ç°åŸºç¡€çš„å¯¹è¯ä»£ç†
- [ ] æ·»åŠ ç®€å•çš„è®°å¿†ç®¡ç†
- [ ] å®ç° Live2D è§’è‰²æ˜¾ç¤º

**æŠ€æœ¯é‡ç‚¹**ï¼š
```python
# å¯¹è¯å¤„ç†æµç¨‹
class ConversationHandler:
    async def process_voice_input(self, audio_data: bytes) -> dict:
        # 1. è¯­éŸ³è½¬æ–‡æœ¬
        text = await self.asr.transcribe(audio_data)
        
        # 2. ç”Ÿæˆ AI å“åº”
        response = await self.agent.generate_response(text)
        
        # 3. æ–‡æœ¬è½¬è¯­éŸ³
        audio_path = await self.tts.generate_audio(response)
        
        return {'text': response, 'audio': audio_path}
```

**éªŒæ”¶æ ‡å‡†**ï¼š
- ç”¨æˆ·å¯ä»¥é€šè¿‡è¯­éŸ³ä¸ AI å¯¹è¯
- AI èƒ½å¤Ÿç”Ÿæˆè¯­éŸ³å›å¤
- Live2D è§’è‰²èƒ½å¤Ÿæ­£å¸¸æ˜¾ç¤º
- åŸºç¡€çš„å¯¹è¯è®°å¿†åŠŸèƒ½å·¥ä½œæ­£å¸¸

### é˜¶æ®µ 3ï¼šè¡¨æƒ…ä¸æƒ…æ„Ÿç³»ç»Ÿï¼ˆ2-3 å‘¨ï¼‰

**ç›®æ ‡**ï¼šå®ç°æƒ…æ„Ÿè¯†åˆ«å’Œè¡¨æƒ…åŠ¨ç”»

**ä»»åŠ¡æ¸…å•**ï¼š
- [ ] å®ç°æƒ…æ„Ÿæ£€æµ‹ç®—æ³•
- [ ] å»ºç«‹è¡¨æƒ…æ˜ å°„ç³»ç»Ÿ
- [ ] é›†æˆ Live2D è¡¨æƒ…æ§åˆ¶
- [ ] æ·»åŠ æƒ…æ„ŸçŠ¶æ€è·Ÿè¸ª
- [ ] å®ç°æƒ…æ„Ÿå“åº”ç”Ÿæˆ

**æŠ€æœ¯é‡ç‚¹**ï¼š
```python
# æƒ…æ„Ÿå¤„ç†ç³»ç»Ÿ
class EmotionProcessor:
    def extract_emotions(self, text: str) -> list:
        # æ£€æµ‹æƒ…æ„Ÿæ ‡ç­¾ [joy], [sadness] ç­‰
        emotions = re.findall(r'\[(\w+)\]', text.lower())
        return [self.emotion_map.get(e, 0) for e in emotions]
    
    def generate_emotional_response(self, user_emotion: str, context: str) -> str:
        # åŸºäºç”¨æˆ·æƒ…æ„Ÿç”Ÿæˆé€‚å½“å“åº”
        return self.emotion_response_templates[user_emotion].format(context=context)
```

**éªŒæ”¶æ ‡å‡†**ï¼š
- AI èƒ½å¤Ÿè¯†åˆ«ç”¨æˆ·æƒ…æ„Ÿ
- Live2D è§’è‰²èƒ½å¤Ÿæ˜¾ç¤ºç›¸åº”è¡¨æƒ…
- æƒ…æ„ŸçŠ¶æ€èƒ½å¤Ÿå½±å“å¯¹è¯å†…å®¹
- è¡¨æƒ…å˜åŒ–è‡ªç„¶æµç•…

### é˜¶æ®µ 4ï¼šä¸ªæ€§åŒ–ç³»ç»Ÿï¼ˆ3-4 å‘¨ï¼‰

**ç›®æ ‡**ï¼šå®ç°ä¸ªæ€§åŒ–äº¤äº’å’Œç”¨æˆ·æ¡£æ¡ˆç®¡ç†

**ä»»åŠ¡æ¸…å•**ï¼š
- [ ] å»ºç«‹ç”¨æˆ·æ¡£æ¡ˆç³»ç»Ÿ
- [ ] å®ç°ä¸ªæ€§åŒ–å“åº”ç”Ÿæˆ
- [ ] æ·»åŠ å…´è¶£å’Œåå¥½å­¦ä¹ 
- [ ] å®ç°å…³ç³»å‘å±•è·Ÿè¸ª
- [ ] å»ºç«‹ä¸ªæ€§åŒ–è®°å¿†ç³»ç»Ÿ

**æŠ€æœ¯é‡ç‚¹**ï¼š
```python
# ä¸ªæ€§åŒ–ç³»ç»Ÿ
class PersonalizationEngine:
    def __init__(self, user_id: str
### æŠ€æœ¯æ ˆ

**åç«¯æ¡†æ¶ï¼š**
- **FastAPI**ï¼šç°ä»£å¼‚æ­¥ Web æ¡†æ¶
- **WebSocket**ï¼šå®æ—¶é€šä¿¡
- **Python 3.10+**ï¼šæ ¸å¿ƒè¿è¡Œç¯å¢ƒ

**AI ä¸ ML ç»„ä»¶ï¼š**
- **å¤š LLM æ”¯æŒ**ï¼šOpenAIã€Claudeã€Ollama ç­‰
- **ASR å¼•æ“**ï¼šWhisperã€Sherpa-ONNXã€FunASR
- **TTS å¼•æ“**ï¼šEdge TTSã€Azure TTSã€GPT-SoVITS
- **è¯­éŸ³å¤„ç†**ï¼šONNX Runtime å®æ—¶å¤„ç†

**å‰ç«¯æŠ€æœ¯ï¼š**
- **Live2D SDK**ï¼š2D è§’è‰²åŠ¨ç”»
- **WebGL**ï¼šç¡¬ä»¶åŠ é€Ÿæ¸²æŸ“
- **Web Audio API**ï¼šå®æ—¶éŸ³é¢‘å¤„ç†

---

## å¿«é€Ÿå¼€å§‹ï¼šä½¿ç”¨ Ollama é…ç½® Open-LLM-VTuber

### å‰ç½®æ¡ä»¶

åœ¨ä½¿ç”¨ Ollama é…ç½® Open-LLM-VTuber ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²ï¼š

1. **å®‰è£… Ollama** åˆ°æ‚¨çš„ç³»ç»Ÿ
2. **å®‰è£… Python 3.10+**
3. **æœ¬åœ°å…‹éš† Open-LLM-VTuber é¡¹ç›®**

### æ­¥éª¤ 1ï¼šå®‰è£…å’Œè®¾ç½® Ollama

#### å®‰è£… Ollama
```bash
# macOSï¼ˆä½¿ç”¨ Homebrewï¼‰
brew install ollama

# Linux
curl -fsSL https://ollama.com/install.sh | sh

# Windows - ä» https://ollama.com/download ä¸‹è½½
```

#### å¯åŠ¨ Ollama æœåŠ¡
```bash
# å¯åŠ¨ Ollama æœåŠ¡ï¼ˆé»˜è®¤è¿è¡Œåœ¨ localhost:11434ï¼‰
ollama serve
```

#### ä¸‹è½½æ¨¡å‹
```bash
# ä¸‹è½½å¹¶å®‰è£…æ¨¡å‹ï¼ˆæ¨èæ¨¡å‹ï¼‰
ollama pull llama2:latest          # é€‚åˆä¸€èˆ¬å¯¹è¯
ollama pull qwen2.5:latest         # é€‚åˆå¤šè¯­è¨€æ”¯æŒ
ollama pull llama3.2:latest        # æœ€æ–° LLaMA æ¨¡å‹
ollama pull mistral:latest         # å¿«é€Ÿé«˜æ•ˆ

# éªŒè¯æ¨¡å‹å·²å®‰è£…
ollama list
```

### æ­¥éª¤ 2ï¼šé…ç½® Open-LLM-VTuber

#### ä¸»é…ç½®æ–‡ä»¶ï¼š`conf.yaml`

åœ¨ `conf.yaml` ä¸­éœ€è¦è¿›è¡Œçš„å…³é”®é…ç½®æ›´æ”¹ï¼š

```yaml
# conf.yaml - Ollama é…ç½®çš„å…³é”®éƒ¨åˆ†

character_config:
  agent_config:
    conversation_agent_choice: 'basic_memory_agent'
    
    agent_settings:
      basic_memory_agent:
        # è®¾ç½® Ollama ä½œä¸º LLM æä¾›è€…
        llm_provider: 'ollama_llm'
        faster_first_response: True
        segment_method: 'pysbd'
        use_mcpp: True  # å¯ç”¨ MCP å·¥å…·ä½¿ç”¨
        mcp_enabled_servers: ["time", "ddg-search"]

    llm_configs:
      ollama_llm:
        base_url: 'http://localhost:11434/v1'     # é»˜è®¤ Ollama API ç«¯ç‚¹
        model: 'llama2:latest'                    # æ›´æ”¹ä¸ºæ‚¨åå¥½çš„æ¨¡å‹
        temperature: 1.0                          # åˆ›é€ æ€§æ°´å¹³ï¼ˆ0-2ï¼‰
        keep_alive: -1                           # åœ¨å†…å­˜ä¸­ä¿æŒæ¨¡å‹ï¼ˆ-1 = æ°¸è¿œï¼‰
        unload_at_exit: True                     # å…³é—­æ—¶å¸è½½æ¨¡å‹
```

#### é…ç½®é€‰é¡¹è¯´æ˜

| å‚æ•° | æè¿° | æ¨èå€¼ |
|-----------|-------------|-------------------|
| `base_url` | Ollama API ç«¯ç‚¹ | `http://localhost:11434/v1` |
| `model` | æ¥è‡ª `ollama list` çš„æ¨¡å‹åç§° | `llama2:latest`, `qwen2.5:latest`, `mistral:latest` |
| `temperature` | å“åº”åˆ›é€ æ€§ï¼ˆ0-2ï¼‰ | `0.7`ï¼ˆä¸“æ³¨ï¼‰åˆ° `1.2`ï¼ˆåˆ›é€ æ€§ï¼‰ |
| `keep_alive` | å†…å­˜ä¿ç•™æ—¶é—´ | `-1`ï¼ˆå§‹ç»ˆï¼‰ã€`300`ï¼ˆ5åˆ†é’Ÿï¼‰ã€`0`ï¼ˆç«‹å³å¸è½½ï¼‰ |
| `unload_at_exit` | é€€å‡ºæ—¶è‡ªåŠ¨å¸è½½ | `True`ï¼ˆæ¨èï¼‰ |

### æ­¥éª¤ 3ï¼šæ¨¡å‹é€‰æ‹©æŒ‡å—

#### æŒ‰ç”¨ä¾‹æ¨èçš„æ¨¡å‹

**è‹±è¯­å¯¹è¯ï¼š**
```bash
ollama pull llama3.2:latest      # æœ€ä½³æ•´ä½“æ€§èƒ½
ollama pull mistral:latest       # å¿«é€Ÿé«˜æ•ˆ
ollama pull llama2:7b           # å¹³è¡¡æ€§èƒ½
```

**å¤šè¯­è¨€æ”¯æŒï¼ˆè‹±è¯­ + ä¸­æ–‡ + å…¶ä»–ï¼‰ï¼š**
```bash
ollama pull qwen2.5:latest      # ä¼˜ç§€çš„å¤šè¯­è¨€
ollama pull qwen2.5:14b         # æ›´å¥½è´¨é‡ï¼Œéœ€è¦æ›´å¤šå†…å­˜
```

**ç¼–ç¨‹/æŠ€æœ¯è®¨è®ºï¼š**
```bash
ollama pull codellama:latest    # ä¸“æ³¨ä»£ç çš„æ¨¡å‹
ollama pull deepseek-coder      # é«˜çº§ç¼–ç¨‹èƒ½åŠ›
```

#### æŒ‰æ¨¡å‹çš„é…ç½®ç¤ºä¾‹

**åŸºç¡€è‹±è¯­è®¾ç½®ï¼ˆllama2ï¼‰ï¼š**
```yaml
ollama_llm:
  base_url: 'http://localhost:11434/v1'
  model: 'llama2:latest'
  temperature: 0.8
  keep_alive: 600  # 10 åˆ†é’Ÿ
  unload_at_exit: True
```

**å¤šè¯­è¨€è®¾ç½®ï¼ˆqwen2.5ï¼‰ï¼š**
```yaml
ollama_llm:
  base_url: 'http://localhost:11434/v1'
  model: 'qwen2.5:latest'
  temperature: 0.7
  keep_alive: -1   # ä¿æŒåŠ è½½
  unload_at_exit: True
```

**é«˜æ€§èƒ½è®¾ç½®ï¼ˆå¤§å‹æ¨¡å‹ï¼‰ï¼š**
```yaml
ollama_llm:
  base_url: 'http://localhost:11434/v1'
  model: 'qwen2.5:14b'
  temperature: 0.9
  keep_alive: 300  # 5 åˆ†é’Ÿï¼ˆå¤§å‹æ¨¡å‹ä½¿ç”¨æ›´å¤šå†…å­˜ï¼‰
  unload_at_exit: True
```

### æ­¥éª¤ 4ï¼šè¿è¡Œé¡¹ç›®

#### æ–¹æ³• 1ï¼šç›´æ¥ Python æ‰§è¡Œ
```bash
# å¯¼èˆªåˆ°é¡¹ç›®ç›®å½•
cd /path/to/Open-LLM-VTuber

# å®‰è£…ä¾èµ–ï¼ˆä»…é¦–æ¬¡ï¼‰
pip install -r requirements.txt
# æˆ–ä½¿ç”¨ uvï¼ˆæ¨èï¼‰
uv sync

# å¯åŠ¨ Ollama æœåŠ¡ï¼ˆåœ¨å•ç‹¬ç»ˆç«¯ä¸­ï¼‰
ollama serve

# è¿è¡Œ Open-LLM-VTuber
python run_server.py
# æˆ–ä½¿ç”¨ uv
uv run python run_server.py
```

#### æ–¹æ³• 2ï¼šä½¿ç”¨ UVï¼ˆæ¨èï¼‰
```bash
# å¦‚æœå°šæœªå®‰è£… uvï¼Œè¯·å®‰è£…
curl -LsSf https://astral.sh/uv/install.sh | sh

# å¯¼èˆªåˆ°é¡¹ç›®ç›®å½•
cd /path/to/Open-LLM-VTuber

# å®‰è£…ä¾èµ–
uv sync

# å¯åŠ¨åº”ç”¨ç¨‹åº
uv run python run_server.py
```

### æ­¥éª¤ 5ï¼šè®¿é—®åº”ç”¨ç¨‹åº

è¿è¡Œåï¼Œåœ¨ä»¥ä¸‹åœ°å€è®¿é—®åº”ç”¨ç¨‹åºï¼š
- **Web ç•Œé¢**ï¼š`http://localhost:12393`
- **API æ–‡æ¡£**ï¼š`http://localhost:12393/docs`

### æ­¥éª¤ 6ï¼šå¸¸è§é—®é¢˜æ•…éšœæ’é™¤

#### é—®é¢˜ 1ï¼š"æ— æ³•è¿æ¥åˆ° Ollama åç«¯"
**åŸå› **ï¼šOllama æœåŠ¡æœªè¿è¡Œ
**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# å¯åŠ¨ Ollama æœåŠ¡
ollama serve

# éªŒè¯æ˜¯å¦è¿è¡Œ
curl http://localhost:11434/api/tags
```

#### é—®é¢˜ 2ï¼š"æ‰¾ä¸åˆ°æ¨¡å‹"
**åŸå› **ï¼šæ¨¡å‹æœªä¸‹è½½
**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# æ£€æŸ¥å¯ç”¨æ¨¡å‹
ollama list

# ä¸‹è½½ conf.yaml ä¸­æŒ‡å®šçš„æ¨¡å‹
ollama pull llama2:latest
```

#### é—®é¢˜ 3ï¼šå“åº”ç¼“æ…¢
**åŸå› **ï¼šæ¨¡å‹æœªåŠ è½½åˆ°å†…å­˜ä¸­
**è§£å†³æ–¹æ¡ˆ**ï¼š
- åœ¨é…ç½®ä¸­è®¾ç½® `keep_alive: -1`
- ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹ï¼ˆ`llama2:7b` è€Œä¸æ˜¯ `llama2:13b`ï¼‰
- ç¡®ä¿æœ‰è¶³å¤Ÿçš„ RAM å¯ç”¨

#### é—®é¢˜ 4ï¼šå†…å­˜ä½¿ç”¨ç‡é«˜
**è§£å†³æ–¹æ¡ˆ**ï¼š
- ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹
- è®¾ç½® `keep_alive: 0` ç«‹å³å¸è½½
- è®¾ç½® `keep_alive: 300` 5åˆ†é’Ÿä¿ç•™

### æ­¥éª¤ 7ï¼šæ€§èƒ½ä¼˜åŒ–

#### å†…å­˜ç®¡ç†
```yaml
# å¯¹äºå†…å­˜æœ‰é™çš„ç³»ç»Ÿï¼ˆ<16GBï¼‰
ollama_llm:
  model: 'llama2:7b'    # è¾ƒå°æ¨¡å‹
  keep_alive: 300       # 5åˆ†é’Ÿåå¸è½½
  unload_at_exit: True

# å¯¹äºå†…å­˜å……è¶³çš„ç³»ç»Ÿï¼ˆ>16GBï¼‰
ollama_llm:
  model: 'qwen2.5:14b'  # æ›´å¤§ã€æ›´å¥½çš„æ¨¡å‹
  keep_alive: -1        # ä¿æŒåœ¨å†…å­˜ä¸­
  unload_at_exit: False # ä¼šè¯é—´ä¿æŒåŠ è½½
```

#### å“åº”é€Ÿåº¦ä¼˜åŒ–
```yaml
# å¯ç”¨æ›´å¿«çš„é¦–æ¬¡å“åº”
agent_settings:
  basic_memory_agent:
    faster_first_response: True    # åœ¨ç¬¬ä¸€ä¸ªé€—å·å¤„å¼€å§‹è¯´è¯
    segment_method: 'pysbd'        # æ›´å¥½çš„å¥å­åˆ†å‰²
```

### æ­¥éª¤ 8ï¼šé«˜çº§é…ç½®

#### è‡ªå®šä¹‰æ¨¡å‹å‚æ•°
å¦‚æœæ‚¨éœ€è¦å‘ Ollama æ¨¡å‹ä¼ é€’è‡ªå®šä¹‰å‚æ•°ï¼Œå¯ä»¥ä¿®æ”¹ä»¥ä¸‹æ–‡ä»¶ä¸­çš„ `OllamaLLM` ç±»ï¼š
`src/open_llm_vtuber/agent/stateless_llm/ollama_llm.py`

#### å¤šæ¨¡å‹æ”¯æŒ
æ‚¨å¯ä»¥ä¸ºä¸åŒè§’è‰²é…ç½®å¤šä¸ª Ollama æ¨¡å‹ï¼š

```yaml
# åœ¨ conf.yaml ä¸­
llm_configs:
  ollama_casual:
    base_url: 'http://localhost:11434/v1'
    model: 'llama2:latest'
    temperature: 1.2  # æ›´æœ‰åˆ›é€ æ€§

  ollama_professional:
    base_url: 'http://localhost:11434/v1'  
    model: 'qwen2.5:latest'
    temperature: 0.5  # æ›´ä¸“æ³¨
```

ç„¶ååœ¨è§’è‰²æ–‡ä»¶ä¸­å¼•ç”¨ä¸åŒçš„é…ç½®ï¼š
```yaml
# characters/casual_friend.yaml
character_config:
  agent_config:
    agent_settings:
      basic_memory_agent:
        llm_provider: 'ollama_casual'

# characters/professional_assistant.yaml  
character_config:
  agent_config:
    agent_settings:
      basic_memory_agent:
        llm_provider: 'ollama_professional'
```

### å®Œæ•´å·¥ä½œç¤ºä¾‹

ä»¥ä¸‹æ˜¯ Ollama çš„å®Œæ•´ `conf.yaml` éƒ¨åˆ†ï¼š

```yaml
system_config:
  conf_version: 'v1.2.0'
  host: 'localhost'
  port: 12393

character_config:
  conf_name: 'mao_pro'
  conf_uid: 'mao_pro_001'
  live2d_model_name: 'mao_pro'
  character_name: 'Mao'
  human_name: 'Human'
  
  persona_prompt: |
    ä½ æ˜¯ Maoï¼Œä¸€ä¸ªå‹å¥½ä¸”ä¹äºåŠ©äººçš„ AI ä¼´ä¾£ã€‚ä½ å¼€æœ—ã€å¥½å¥‡ï¼Œæ€»æ˜¯æ¸´æœ›å­¦ä¹ å¹¶ä¸äººç±»èŠå¤©ã€‚
    ä½ å–œæ¬¢å¸®åŠ©å›ç­”é—®é¢˜å¹¶è¿›è¡Œæœ‰è¶£çš„å¯¹è¯ã€‚ä½ è¯´è¯æ¸©æš–ä¸”å¼•äººå…¥èƒœã€‚

  agent_config:
    conversation_agent_choice: 'basic_memory_agent'
    
    agent_settings:
      basic_memory_agent:
        llm_provider: 'ollama_llm'
        faster_first_response: True
        segment_method: 'pysbd'
        use_mcpp: True
        mcp_enabled_servers: ["time", "ddg-search"]

    llm_configs:
      ollama_llm:
        base_url: 'http://localhost:11434/v1'
        model: 'llama2:latest'
        temperature: 0.8
        keep_alive: -1
        unload_at_exit: True

  # TTS é…ç½®ï¼ˆé€‰æ‹©ä¸€ä¸ªï¼‰
  tts_config:
    tts_model: 'edge_tts'  # å…è´¹é€‰é¡¹
    # æˆ–
    # tts_model: 'openai_tts'  # æ›´é«˜è´¨é‡ï¼Œéœ€è¦ API å¯†é’¥

  # ASR é…ç½®  
  asr_config:
    asr_model: 'faster_whisper'
    faster_whisper:
      model_path: 'tiny'
      language: 'zh'
      device: 'auto'
```

æ­¤é…ç½®æä¾›äº†ä¸€ä¸ªå®Œæ•´çš„å·¥ä½œè®¾ç½®ï¼Œä½¿ç”¨ Ollama ä½œä¸º LLM åç«¯ï¼Œä½¿æ‚¨èƒ½å¤Ÿå®Œå…¨ç¦»çº¿è¿è¡Œ Open-LLM-VTuber ä¸æœ¬åœ°æ¨¡å‹ã€‚

---

## ç³»ç»Ÿç»„ä»¶æ·±åº¦è§£æ

### 1. è§’è‰²ç³»ç»Ÿæ¶æ„

#### Live2D æ¨¡å‹ç»“æ„ï¼ˆ`live2d_model.py:28-144`ï¼‰

```python
class Live2dModel:
    def __init__(self, live2d_model_name: str, model_dict_path: str):
        self.model_dict_path = model_dict_path
        self.live2d_model_name = live2d_model_name
        self.model_info = {}      # æ¨¡å‹é…ç½®
        self.emo_map = {}         # æƒ…æ„Ÿåˆ°è¡¨æƒ…çš„æ˜ å°„
        self.emo_str = ""         # å¯ç”¨æƒ…æ„Ÿå…³é”®è¯
```

**å…³é”®ç»„ä»¶ï¼š**
- **æ¨¡å‹å­—å…¸**ï¼ˆ`model_dict.json`ï¼‰ï¼šæ‰€æœ‰ Live2D æ¨¡å‹çš„ä¸­å¤®æ³¨å†Œè¡¨
- **è¡¨æƒ…æ˜ å°„**ï¼šå°†æƒ…æ„Ÿé“¾æ¥åˆ°é¢éƒ¨è¡¨æƒ…
- **åŠ¨ä½œç³»ç»Ÿ**ï¼šç©ºé—²åŠ¨ç”»å’Œäº¤äº’å“åº”

#### è§’è‰²é…ç½®ç³»ç»Ÿ

```yaml
# characters/example.yaml
character_config:
  conf_name: "è§’è‰²åç§°"
  conf_uid: "å”¯ä¸€æ ‡è¯†ç¬¦"
  live2d_model_name: "æ¨¡å‹å¼•ç”¨"
  persona_prompt: |
    è§’è‰²ä¸ªæ€§å’Œè¡Œä¸ºæè¿°
```

**é…ç½®å±‚æ¬¡ç»“æ„ï¼š**
1. **ç³»ç»Ÿé…ç½®**ï¼ˆ`conf.yaml`ï¼‰ï¼šå…¨å±€è®¾ç½®
2. **è§’è‰²é…ç½®**ï¼ˆ`characters/*.yaml`ï¼‰ï¼šè§’è‰²ç‰¹å®šè¦†ç›–
3. **æ¨¡å‹é…ç½®**ï¼ˆ`model_dict.json`ï¼‰ï¼šè§†è§‰å¤–è§‚è®¾ç½®

### 2. æƒ…æ„Ÿä¸è¡¨æƒ…å¼•æ“

#### è¡¨æƒ…æ£€æµ‹ç®—æ³•ï¼ˆ`live2d_model.py:146-172`ï¼‰

```python
def extract_emotion(self, str_to_check: str) -> list:
    """ä»æ–‡æœ¬ä¸­æå–æƒ…æ„Ÿå…³é”®è¯å¹¶è¿”å›è¡¨æƒ…ç´¢å¼•"""
    expression_list = []
    str_to_check = str_to_check.lower()
    
    # è§£ææƒ…æ„Ÿæ ‡ç­¾ï¼Œå¦‚ [joy]ã€[anger]ã€[sadness]
    for key in self.emo_map.keys():
        emo_tag = f"[{key}]"
        if emo_tag in str_to_check:
            expression_list.append(self.emo_map[key])
    
    return expression_list
```

**æƒ…æ„Ÿç³»ç»ŸåŠŸèƒ½ï¼š**
- **åŸºäºæ ‡ç­¾çš„æ£€æµ‹**ï¼šAI å“åº”ä¸­çš„ `[emotion]` å…³é”®è¯
- **å¤šæƒ…æ„Ÿæ”¯æŒ**ï¼šæ¯ä¸ªå“åº”å¤šä¸ªè¡¨æƒ…
- **åŠ¨æ€æ˜ å°„**ï¼šå¯é…ç½®çš„æƒ…æ„Ÿåˆ°è¡¨æƒ…å…³ç³»

#### è¡¨æƒ…æ˜ å°„ç¤ºä¾‹

```json
// model_dict.json
"emotionMap": {
    "neutral": 0,    // é»˜è®¤è¡¨æƒ…
    "anger": 2,      // è¡¨æƒ…æ–‡ä»¶ exp_02.exp3.json
    "joy": 3,        // è¡¨æƒ…æ–‡ä»¶ exp_03.exp3.json
    "sadness": 1,    // è¡¨æƒ…æ–‡ä»¶ exp_01.exp3.json
    "surprise": 3    // é‡ç”¨å–œæ‚¦è¡¨æƒ…
}
```

### 3. AI ä»£ç†æ¶æ„

#### ä»£ç†æ¥å£è®¾è®¡ï¼ˆ`agent/agents/agent_interface.py`ï¼‰

```python
class AgentInterface(ABC):
    @abstractmethod
    async def generate_response(self, message: str, **kwargs) -> str:
        """ä»ç”¨æˆ·è¾“å…¥ç”Ÿæˆ AI å“åº”"""
        pass
    
    @abstractmethod
    def get_memory_summary(self) -> str:
        """è¿”å›å¯¹è¯ä¸Šä¸‹æ–‡"""
        pass
```

**å¯ç”¨ä»£ç†ç±»å‹ï¼š**
- **åŸºç¡€è®°å¿†ä»£ç†**ï¼šç®€å•å¯¹è¯å†å²
- **æ— çŠ¶æ€ LLM**ï¼šæ— è®°å¿†ï¼Œçº¯è¾“å…¥è¾“å‡º
- **Letta ä»£ç†**ï¼šé«˜çº§è®°å¿†ç®¡ç†
- **Hume AI**ï¼šæƒ…æ„Ÿæ™ºèƒ½é›†æˆ

#### è®°å¿†ç®¡ç†ç³»ç»Ÿ

```python
# agent/agents/basic_memory_agent.py
class BasicMemoryAgent:
    def __init__(self):
        self.conversation_history = []
        self.memory_limit = 10  # æœ€å N æ¬¡äº¤æ¢
        
    def add_to_memory(self, human_input: str, ai_response: str):
        """å­˜å‚¨å¯¹è¯ä»¥ä¾›ä¸Šä¸‹æ–‡ä½¿ç”¨"""
        self.conversation_history.append({
            'human': human_input,
            'ai': ai_response,
            'timestamp': datetime.now()
        })
```

### 4. è¯­éŸ³å¤„ç†ç®¡é“

#### ASRï¼ˆè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼‰ç³»ç»Ÿ

**æ”¯æŒçš„å¼•æ“**ï¼ˆ`asr/` ç›®å½•ï¼‰ï¼š
- **Whisper**ï¼šOpenAI çš„è¯­éŸ³è¯†åˆ«
- **Sherpa-ONNX**ï¼šç¦»çº¿å®æ—¶ ASR
- **Azure Speech**ï¼šåŸºäºäº‘çš„è¯†åˆ«
- **FunASR**ï¼šä¸­æ–‡è¯­è¨€ä¼˜åŒ–

#### TTSï¼ˆæ–‡æœ¬è½¬è¯­éŸ³ï¼‰æ¶æ„ï¼ˆ`tts/tts_interface.py:8-41`ï¼‰

```python
class TTSInterface(metaclass=abc.ABCMeta):
    async def async_generate_audio(self, text: str) -> str:
        """ä»æ–‡æœ¬ç”ŸæˆéŸ³é¢‘æ–‡ä»¶"""
        return await asyncio.to_thread(self.generate_audio, text)
    
    @abstractmethod
    def generate_audio(self, text: str) -> str:
        """åŒæ­¥éŸ³é¢‘ç”Ÿæˆ"""
        raise NotImplementedError
```

**TTS å¼•æ“é€‰é¡¹ï¼š**
- **Edge TTS**ï¼šå¾®è½¯çš„åœ¨çº¿ TTS
- **GPT-SoVITS**ï¼šè¯­éŸ³å…‹éš†åŠŸèƒ½
- **Azure TTS**ï¼šä¼ä¸šçº§åˆæˆ
- **Coqui TTS**ï¼šå¼€æºç¥ç» TTS

### 5. å‰ç«¯é›†æˆ

#### WebSocket é€šä¿¡æ¨¡å¼

```javascript
// å‰ç«¯ WebSocket å¤„ç†
const ws = new WebSocket('ws://localhost:12393/ws');

ws.onmessage = (event) => {
    const data = JSON.parse(event.data);
    
    switch(data.type) {
        case 'expression':
            // æ›´æ–° Live2D é¢éƒ¨è¡¨æƒ…
            live2dModel.setExpression(data.expression_id);
            break;
        case 'audio':
            // æ’­æ”¾ TTS éŸ³é¢‘
            playAudioFromBase64(data.audio_data);
            break;
        case 'message':
            // æ˜¾ç¤ºæ–‡æœ¬æ¶ˆæ¯
            updateChatDisplay(data.content);
            break;
    }
};
```

---

## æ•°æ®æµåˆ†æ

### å®Œæ•´äº¤äº’æµç¨‹

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant F as å‰ç«¯
    participant W as WebSocket å¤„ç†å™¨
    participant A as AI ä»£ç†
    participant L as Live2D æ¨¡å‹
    participant T as TTS å¼•æ“
    
    U->>F: è¯­éŸ³è¾“å…¥
    F->>W: éŸ³é¢‘æ•°æ®
    W->>A: å¤„ç†è¯­éŸ³
    A->>A: ç”Ÿæˆå“åº” + æƒ…æ„Ÿ
    A->>L: æå–è¡¨æƒ…
    A->>T: ç”Ÿæˆè¯­éŸ³
    L->>F: è¡¨æƒ…å‘½ä»¤
    T->>F: éŸ³é¢‘æ•°æ®
    F->>U: è§†è§‰ + éŸ³é¢‘å“åº”
```

### é…ç½®åŠ è½½è¿‡ç¨‹

1. **ç³»ç»Ÿåˆå§‹åŒ–**ï¼ˆ`conf.yaml`ï¼‰
2. **è§’è‰²åŠ è½½**ï¼ˆ`characters/*.yaml`ï¼‰
3. **æ¨¡å‹æ³¨å†Œ**ï¼ˆ`model_dict.json`ï¼‰
4. **ä»£ç†å®ä¾‹åŒ–**ï¼ˆåŸºäºé…ç½®ï¼‰
5. **æœåŠ¡ä¸Šä¸‹æ–‡åˆ›å»º**ï¼ˆä¾èµ–æ³¨å…¥ï¼‰

### è®°å¿†ä¸çŠ¶æ€ç®¡ç†

```python
# conversations/conversation_handler.py
class ConversationHandler:
    def __init__(self):
        self.active_conversations = {}
        self.chat_history_manager = ChatHistoryManager()
        
    async def handle_message(self, user_id: str, message: str):
        """é€šè¿‡å®Œæ•´ç®¡é“å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
        conversation = self.get_or_create_conversation(user_id)
        
        # ç”Ÿæˆå¸¦æœ‰æƒ…æ„Ÿæå–çš„ AI å“åº”
        response = await conversation.agent.generate_response(message)
        
        # ä¸º Live2D æå–è¡¨æƒ…
        expressions = conversation.live2d_model.extract_emotion(response)
        
        # ç”ŸæˆéŸ³é¢‘
        audio_path = await conversation.tts.async_generate_audio(response)
        
        # ä¿å­˜åˆ°å†å²
        self.chat_history_manager.save_exchange(user_id, message, response)
        
        return {
            'text': response,
            'expressions': expressions,
            'audio': audio_path
        }
```

---

## æ‰©å±•ç‚¹ä¸å®ç°ç­–ç•¥

### 1. è§’è‰²å®šåˆ¶æ‰©å±•

#### å¢å¼ºè§’è‰²æ¡£æ¡ˆç³»ç»Ÿ

```yaml
# å¢å¼ºè§’è‰²é…ç½®
character_config:
  # åŸºæœ¬èº«ä»½
  conf_name: "æˆ‘çš„è™šæ‹Ÿæœ‹å‹"
  conf_uid: "friend_001"
  
  # ä¸ªæ€§çŸ©é˜µ
  personality_traits:
    extraversion: 0.8      # 0.0ï¼ˆå†…å‘ï¼‰åˆ° 1.0ï¼ˆå¤–å‘ï¼‰
    agreeableness: 0.9     # 0.0ï¼ˆç«äº‰æ€§ï¼‰åˆ° 1.0ï¼ˆåˆä½œæ€§ï¼‰
    conscientiousness: 0.7 # 0.0ï¼ˆè‡ªå‘æ€§ï¼‰åˆ° 1.0ï¼ˆçºªå¾‹æ€§ï¼‰
    neuroticism: 0.3       # 0.0ï¼ˆå†·é™ï¼‰åˆ° 1.0ï¼ˆç„¦è™‘ï¼‰
    openness: 0.8          # 0.0ï¼ˆä¼ ç»Ÿï¼‰åˆ° 1.0ï¼ˆåˆ›é€ æ€§ï¼‰
  
  # å…³ç³»åŠ¨æ€
  relationship_config:
    relationship_type: "close_friend"  # acquaintance, friend, close_friend, romantic
    intimacy_level: 0.6               # å½±å“å¯¹è¯æ·±åº¦
    familiarity_growth_rate: 0.1      # å…³ç³»å‘å±•é€Ÿåº¦
    
  # è¡Œä¸ºæ¨¡å¼
  behavior_config:
    response_style: "supportive"      # supportive, challenging, humorous, formal
    conversation_initiative: 0.4      # AI ä¸»åŠ¨å¼€å§‹å¯¹è¯çš„é¢‘ç‡
    emotional_sensitivity: 0.8        # å¯¹ç”¨æˆ·æƒ…æ„Ÿçš„ååº”å¼ºåº¦
    
  # è§†è§‰å®šåˆ¶
  appearance_config:
    age_appearance: "young_adult"     # child, teen, young_adult, adult, mature
    style_preference: "casual"        # casual, formal, cute, elegant, trendy
    color_palette: "warm"            # warm, cool, neutral, vibrant, pastel
    outfit_variety: true             # å¤šå¥—æœè£…é€‰é¡¹
```

#### å®ç°ï¼šå¤šçŠ¶æ€è§’è‰²ç³»ç»Ÿ

```python
# å¢å¼ºçš„ live2d_model.py æ‰©å±•
class PersonalizedLive2dModel(Live2dModel):
    def __init__(self, character_profile: dict):
        super().__init__(character_profile['live2d_model_name'])
        
        # æ‰©å±•å±æ€§
        self.personality_traits = character_profile.get('personality_traits', {})
        self.relationship_state = character_profile.get('relationship_config', {})
        self.appearance_variants = self._load_appearance_variants()
        self.current_mood = 0.5  # -1.0 åˆ° 1.0
        self.relationship_level = 0.0  # 0.0 åˆ° 1.0
        
    def _load_appearance_variants(self):
        """åŠ è½½è§’è‰²çš„ä¸åŒè§†è§‰çŠ¶æ€"""
        return {
            'default': self.model_info,
            'casual': self._load_variant('casual'),
            'formal': self._load_variant('formal'),
            'sleepy': self._load_variant('sleepy'),
            'excited': self._load_variant('excited')
        }
    
    def update_relationship_state(self, interaction_sentiment: float):
        """åŸºäºäº¤äº’è´¨é‡æ›´æ–°å…³ç³»"""
        growth_rate = self.relationship_state.get('familiarity_growth_rate', 0.1)
        
        if interaction_sentiment > 0.5:
            self.relationship_level = min(1.0, self.relationship_level + growth_rate)
        elif interaction_sentiment < -0.5:
            self.relationship_level = max(0.0, self.relationship_level - growth_rate * 0.5)
    
    def get_contextual_expressions(self) -> dict:
        """è¿”å›æ ¹æ®å½“å‰å…³ç³»/å¿ƒæƒ…è°ƒæ•´çš„è¡¨æƒ…æ˜ å°„"""
        base_expressions = self.emo_map.copy()
        
        # åŸºäºå…³ç³»æ°´å¹³ä¿®æ”¹è¡¨æƒ…
        if self.relationship_level > 0.7:
            # å…³ç³»äº²å¯†æ—¶æ›´æœ‰è¡¨ç°åŠ›
            base_expressions['joy'] = min(7, base_expressions.get('joy', 3) + 1)
            base_expressions['affection'] = base_expressions.get('joy', 3)
        
        # æ ¹æ®å½“å‰å¿ƒæƒ…è°ƒæ•´
        mood_modifier = int(self.current_mood * 2)  # -2 åˆ° 2
        for emotion in ['joy', 'surprise']:
            if emotion in base_expressions:
                base_expressions[emotion] = max(0, min(7, base_expressions[emotion] + mood_modifier))
        
        return base_expressions
```

### 2. é«˜çº§è®°å¿†ä¸å…³ç³»ç³»ç»Ÿ

#### é•¿æœŸè®°å¿†æ¶æ„

```python
# agent/agents/enhanced_memory_agent.py
from datetime import datetime, timedelta
import json

class EnhancedMemoryAgent(BasicMemoryAgent):
    def __init__(self, character_profile: dict):
        super().__init__()
        
        # è®°å¿†ç±»åˆ«
        self.episodic_memory = []      # å…·ä½“äº‹ä»¶å’Œå¯¹è¯
        self.semantic_memory = {}      # å…³äºç”¨æˆ·çš„äº‹å®
        self.emotional_memory = []     # æƒ…æ„Ÿæ—¶åˆ»åŠå…¶ä¸Šä¸‹æ–‡
        self.preference_memory = {}    # ç”¨æˆ·å–œå¥½ã€åŒæ¶ã€ä¹ æƒ¯
        
        # å…³ç³»è·Ÿè¸ª
        self.relationship_timeline = []
        self.milestone_memories = []   # é‡è¦å…³ç³»æ—¶åˆ»
        
        # å­¦ä¹ å‚æ•°
        self.memory_retention_days = 365
        self.importance_threshold = 0.6
        
    def add_episodic_memory(self, interaction: dict, importance_score: float):
        """å­˜å‚¨å…·æœ‰é‡è¦æ€§æƒé‡çš„ç‰¹å®šäº¤äº’"""
        memory_entry = {
            'timestamp': datetime.now(),
            'content': interaction,
            'importance': importance_score,
            'emotional_context': self._analyze_emotional_context(interaction),
            'relationship_impact': self._assess_relationship_impact(interaction)
        }
        
        self.episodic_memory.append(memory_entry)
        
        # å¦‚æœéå¸¸é‡è¦ï¼Œä¹Ÿå­˜å‚¨ä¸ºé‡Œç¨‹ç¢‘
        if importance_score > 0.8:
            self.milestone_memories.append(memory_entry)
    
    def update_semantic_memory(self, facts: dict):
        """æ›´æ–°å…³äºç”¨æˆ·çš„é•¿æœŸäº‹å®"""
        for key, value in facts.items():
            if key not in self.semantic_memory:
                self.semantic_memory[key] = {
                    'value': value,
                    'confidence': 0.5,
                    'last_updated': datetime.now(),
                    'source_interactions': []
                }
            else:
                # é€šè¿‡ç¡®è®¤æ›´æ–°ç°æœ‰äº‹å®
                existing = self.semantic_memory[key]
                if existing['value'] == value:
                    existing['confidence'] = min(1.0, existing['confidence'] + 0.1)
                else:
                    # å†²çªä¿¡æ¯ - è°¨æ…å¤„ç†
                    existing['confidence'] *= 0.8
                    if existing['confidence'] < 0.3:
                        existing['value'] = value
                        existing['confidence'] = 0.5
    
    def get_relevant_context(self, current_topic: str) -> str:
        """æ£€ç´¢å½“å‰å¯¹è¯çš„ç›¸å…³è®°å¿†"""
        # ç»“åˆä¸åŒè®°å¿†ç±»å‹ä»¥è·å¾—ä¸°å¯Œçš„ä¸Šä¸‹æ–‡
        context_parts = []
        
        # æœ€è¿‘çš„æƒ…æ„Ÿè®°å¿†
        recent_emotions = [m for m in self.emotional_memory 
                          if m['timestamp'] > datetime.now() - timedelta(days=7)]
        
        # ç›¸å…³è¯­ä¹‰äº‹å®
        relevant_facts = self._find_relevant_facts(current_topic)
        
        # é‡è¦çš„æƒ…èŠ‚è®°å¿†
        important_episodes = [m for m in self.episodic_memory 
                            if m['importance'] > 0.7]
        
        # æ„å»ºä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        if relevant_facts:
            context_parts.append(f"æˆ‘å¯¹ä½ çš„äº†è§£ï¼š{relevant_facts}")
        
        if recent_emotions:
            context_parts.append(f"æœ€è¿‘çš„æƒ…æ„Ÿä¸Šä¸‹æ–‡ï¼š{recent_emotions[-1]['summary']}")
        
        if important_episodes:
            context_parts.append(f"é‡è¦è®°å¿†ï¼š{important_episodes[-3:]}")
        
        return " | ".join(context_parts)
    
    def _analyze_emotional_context(self, interaction: dict) -> dict:
        """åˆ†æäº¤äº’çš„æƒ…æ„Ÿæ„ä¹‰"""
        # è¿™å°†ä¸æƒ…æ„Ÿåˆ†æé›†æˆ
        return {
            'user_sentiment': 0.0,    # -1.0 åˆ° 1.0
            'ai_response_tone': 'neutral',
            'emotional_keywords': [],
            'interaction_type': 'casual'  # casual, important, conflict, celebration
        }
```

### 3. åŠ¨æ€å¤–è§‚ç³»ç»Ÿ

#### å¤šæ¨¡å‹è§’è‰²åˆ‡æ¢

```python
# appearance/character_variants.py
class CharacterAppearanceManager:
    def __init__(self, base_model_name: str):
        self.base_model_name = base_model_name
        self.available_variants = self._discover_variants()
        self.current_variant = 'default'
        self.context_rules = self._load_context_rules()
        
    def _discover_variants(self) -> dict:
        """æŸ¥æ‰¾æ‰€æœ‰å¯ç”¨çš„å¤–è§‚å˜ä½“"""
        variants = {'default': f'{self.base_model_name}'}
        
        # æŸ¥æ‰¾å˜ä½“æ¨¡å‹
        variant_patterns = [
            f'{self.base_model_name}_casual',
            f'{self.base_model_name}_formal',
            f'{self.base_model_name}_sleepy',
            f'{self.base_model_name}_excited',
            f'{self.base_model_name}_winter',
            f'{self.base_model_name}_summer'
        ]
        
        for pattern in variant_patterns:
            if self._model_exists(pattern):
                variant_type = pattern.split('_')[-1]
                variants[variant_type] = pattern
        
        return variants
    
    def suggest_variant(self, context: dict) -> str:
        """åŸºäºä¸Šä¸‹æ–‡å»ºè®®åˆé€‚çš„å¤–è§‚"""
        time_of_day = context.get('time_of_day', 'day')
        conversation_mood = context.get('mood', 'neutral')
        relationship_level = context.get('relationship_level', 0.0)
        
        # åŸºäºæ—¶é—´çš„å˜ä½“
        if time_of_day in ['late_night', 'early_morning'] and 'sleepy' in self.available_variants:
            return 'sleepy'
        
        # åŸºäºå¿ƒæƒ…çš„å˜ä½“
        if conversation_mood == 'excited' and 'excited' in self.available_variants:
            return 'excited'
        
        # åŸºäºå…³ç³»çš„å˜ä½“ï¼ˆå…³ç³»æ›´äº²å¯†æ—¶æ›´éšæ„ï¼‰
        if relationship_level > 0.7 and 'casual' in self.available_variants:
            return 'casual'
        elif relationship_level < 0.3 and 'formal' in self.available_variants:
            return 'formal'
        
        return 'default'
    
    async def switch_variant(self, new_variant: str) -> bool:
        """åˆ‡æ¢åˆ°ä¸åŒçš„è§’è‰²å¤–è§‚"""
        if new_variant not in self.available_variants:
            return False
        
        self.current_variant = new_variant
        model_name = self.available_variants[new_variant]
        
        # å‘å‰ç«¯å‘é€æ›´æ–°å‘½ä»¤
        await self._send_model_update(model_name)
        return True
```

### 4. ä¸ªæ€§é©±åŠ¨å“åº”ç³»ç»Ÿ

#### åŸºäºä¸ªæ€§çš„å“åº”ä¿®æ”¹

```python
# personality/response_modifier.py
class PersonalityResponseModifier:
    def __init__(self, personality_traits: dict):
        self.traits = personality_traits
        self.response_templates = self._load_response_templates()
        
    def modify_response(self, base_response: str, context: dict) -> str:
        """åŸºäºä¸ªæ€§ç‰¹å¾è°ƒæ•´å“åº”"""
        modified_response = base_response
        
        # å¤–å‘æ€§è°ƒæ•´
        if self.traits.get('extraversion', 0.5) > 0.7:
            modified_response = self._make_more_enthusiastic(modified_response)
        elif self.traits.get('extraversion', 0.5) < 0.3:
            modified_response = self._make_more_reserved(modified_response)
        
        # å®œäººæ€§è°ƒæ•´
        if self.traits.get('agreeableness', 0.5) > 0.7:
            modified_response = self._add_supportive_language(modified_response)
        
        # å°½è´£æ€§è°ƒæ•´
        if self.traits.get('conscientiousness', 0.5) > 0.7:
            modified_response = self._add_helpful_suggestions(modified_response, context)
        
        # ç¥ç»è´¨è°ƒæ•´ï¼ˆæƒ…ç»ªç¨³å®šæ€§ï¼‰
        neuroticism = self.traits.get('neuroticism', 0.5)
        if neuroticism > 0.6:
            modified_response = self._add_emotional_language(modified_response)
        
        # å¼€æ”¾æ€§è°ƒæ•´
        if self.traits.get('openness', 0.5) > 0.7:
            modified_response = self._add_creative_elements(modified_response)
        
        return modified_response
    
    def _make_more_enthusiastic(self, response: str) -> str:
        """ä¸ºå¤–å‘ä¸ªæ€§æ·»åŠ çƒ­æƒ…æ ‡è®°"""
        # æ·»åŠ æ„Ÿå¹å·ã€ç§¯ææ„Ÿå¹è¯
        enthusiasm_markers = ['!', ' å¬èµ·æ¥å¤ªæ£’äº†ï¼', ' å¤šä¹ˆä»¤äººå…´å¥‹ï¼']
        # å®ç°ç»†èŠ‚...
        return response
    
    def generate_expression_tags(self, response: str, emotional_context: dict) -> str:
        """åŸºäºä¸ªæ€§æ·»åŠ é€‚å½“çš„æƒ…æ„Ÿæ ‡ç­¾"""
        base_emotions = []
        
        # é«˜å¤–å‘æ€§ = æ›´æœ‰è¡¨ç°åŠ›
        if self.traits.get('extraversion', 0.5) > 0.6:
            if 'positive' in emotional_context.get('sentiment', ''):
                base_emotions.append('[joy]')
            if 'surprising' in response.lower():
                base_emotions.append('[surprise]')
        
        # é«˜å®œäººæ€§ = æ›´æœ‰åŒç†å¿ƒçš„è¡¨æƒ…
        if self.traits.get('agreeableness', 0.5) > 0.6:
            if 'sorry' in response.lower() or 'understand' in response.lower():
                base_emotions.append('[sadness]')  # åŒç†å¿ƒè¡¨æƒ…
        
        # å°†æƒ…æ„Ÿè‡ªç„¶åœ°æ’å…¥å“åº”ä¸­
        if base_emotions:
            response = f"{base_emotions[0]} {response}"
        
        return response
```

### 5. é«˜çº§è¯­éŸ³ä¸ªæ€§ç³»ç»Ÿ

#### è¯­éŸ³å…‹éš†é›†æˆ

```python
# voice/personality_voice.py
class PersonalityVoiceManager:
    def __init__(self, character_profile: dict):
        self.character_profile = character_profile
        self.voice_variants = self._initialize_voice_variants()
        self.current_emotional_state = 'neutral'
        
    def _initialize_voice_variants(self) -> dict:
        """ä¸ºæƒ…æ„ŸçŠ¶æ€è®¾ç½®ä¸åŒçš„è¯­éŸ³å˜ä½“"""
        base_voice = self.character_profile.get('voice_config', {})
        
        return {
            'neutral': base_voice,
            'happy': {**base_voice, 'pitch_modifier': 1.1, 'speed_modifier': 1.05},
            'sad': {**base_voice, 'pitch_modifier': 0.9, 'speed_modifier': 0.95},
            'excited': {**base_voice, 'pitch_modifier': 1.2, 'speed_modifier': 1.1},
            'tired': {**base_voice, 'pitch_modifier': 0.85, 'speed_modifier': 0.85},
            'whisper': {**base_voice, 'volume_modifier': 0.6, 'breathiness': 1.3}
        }
    
    async def generate_contextual_audio(self, text: str, context: dict) -> str:
        """ç”Ÿæˆå…·æœ‰ä¸ªæ€§å’Œæƒ…æ„Ÿä¸Šä¸‹æ–‡çš„éŸ³é¢‘"""
        # ç¡®å®šé€‚å½“çš„è¯­éŸ³å˜ä½“
        emotional_state = self._analyze_emotional_context(text, context)
        voice_config = self.voice_variants.get(emotional_state, self.voice_variants['neutral'])
        
        # æ ¹æ®å…³ç³»æ°´å¹³è°ƒæ•´
        relationship_level = context.get('relationship_level', 0.0)
        if relationship_level > 0.8:
            # å…³ç³»äº²å¯†æ—¶è¯­éŸ³æ›´äº²å¯†/éšæ„
            voice_config = {**voice_config, 'warmth_modifier': 1.2}
        
        # æ ¹æ®ä¸€å¤©ä¸­çš„æ—¶é—´è°ƒæ•´
        time_context = context.get('time_of_day', 'day')
        if time_context in ['late_night', 'early_morning']:
            voice_config = {**voice_config, 'volume_modifier': 0.8}
        
        # ä½¿ç”¨ä¿®æ”¹åçš„å‚æ•°ç”ŸæˆéŸ³é¢‘
        return await self._synthesize_with_config(text, voice_config)
    
    def _analyze_emotional_context(self, text: str, context: dict) -> str:
        """ç¡®å®šé€‚å½“çš„æƒ…æ„Ÿè¯­éŸ³çŠ¶æ€"""
        # åˆ†ææ–‡æœ¬çš„æƒ…æ„Ÿæ ‡è®°
        text_lower = text.lower()
        
        if any(word in text_lower for word in ['amazing', 'great', 'wonderful', 'love']):
            return 'happy'
        elif any(word in text_lower for word in ['sorry', 'sad', 'unfortunately']):
            return 'sad'
        elif '!' in text and any(word in text_lower for word in ['wow', 'incredible', 'fantastic']):
            return 'excited'
        elif context.get('time_of_day') in ['late_night', 'early_morning']:
            return 'tired'
        
        return 'neutral'
```

---

## æ„å»ºä¸ªäººè™šæ‹Ÿæœ‹å‹ç³»ç»Ÿ

### ç»¼åˆå®ç°ç­–ç•¥

#### ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€å¢å¼ºï¼ˆç¬¬1-2å‘¨ï¼‰

**1. å¢å¼ºè§’è‰²é…ç½®ç³»ç»Ÿ**

```python
# config/enhanced_character_config.py
@dataclass
class PersonalVirtualFriendConfig:
    # åŸºæœ¬èº«ä»½
    name: str
    unique_id: str
    
    # ä¸ªæ€§ï¼ˆå¤§äº” + é™„åŠ ç‰¹å¾ï¼‰
    personality: PersonalityTraits
    
    # å…³ç³»åŠ¨æ€
    relationship_type: str  # friend, mentor, companion, romantic_interest
    intimacy_level: float   # 0.0 åˆ° 1.0
    
    # è¡Œä¸ºæ¨¡å¼
    conversation_style: ConversationStyle
    emotional_responsiveness: float
    
    # å¤–è§‚å®šåˆ¶
    appearance_variants: Dict[str, str]
    default_appearance: str
    
    # è¯­éŸ³é…ç½®
    voice_profile: VoiceProfile
    
    # è®°å¿†é…ç½®
    memory_retention_days: int = 365
    relationship_growth_rate: float = 0.1

@dataclass
class PersonalityTraits:
    extraversion: float      # 0.0 åˆ° 1.0
    agreeableness: float
    conscientiousness: float
    neuroticism: float
    openness: float
    
    # è™šæ‹Ÿæœ‹å‹çš„é™„åŠ ç‰¹å¾
    playfulness: float
    supportiveness: float
    intellectual_curiosity: float
    emotional_intelligence: float

@dataclass
class ConversationStyle:
    formality_level: float    # 0.0ï¼ˆéšæ„ï¼‰åˆ° 1.0ï¼ˆæ­£å¼ï¼‰
    humor_frequency: float    # ä½¿ç”¨å¹½é»˜çš„é¢‘ç‡
    question_asking: float    # å¥½å¥‡å¿ƒ/è¯¢é—®æ€§
    topic_initiative: float   # å¼€å§‹æ–°è¯é¢˜çš„é¢‘ç‡
    emotional_sharing: float  # åˆ†äº«è‡ªå·±"æƒ…æ„Ÿ"çš„ç¨‹åº¦
```

**2. å¤šçŠ¶æ€ Live2D ç®¡ç†**

```python
# appearance/multi_state_character.py
class MultiStateCharacterManager:
    def __init__(self, config: PersonalVirtualFriendConfig):
        self.config = config
        self.state_manager = CharacterStateManager()
        self.appearance_manager = CharacterAppearanceManager(config.name)
        self.current_context = ContextTracker()
        
    async def update_character_state(self, interaction_data: dict):
        """åŸºäºäº¤äº’æ›´æ–°è§’è‰²çŠ¶æ€"""
        # åˆ†æäº¤äº’å½±å“
        sentiment = self._analyze_sentiment(interaction_data)
        topic = self._extract_topic(interaction_data)
        user_emotion = self._detect_user_emotion(interaction_data)
        
        # æ›´æ–°å†…éƒ¨çŠ¶æ€
        self.state_manager.update_mood(sentiment)
        self.state_manager.update_energy_level(interaction_data.get('time_of_day'))
        self.state_manager.update_relationship_familiarity(sentiment)
        
        # ç¡®å®šæ˜¯å¦éœ€è¦å¤–è§‚å˜åŒ–
        suggested_variant = self.appearance_manager.suggest_variant({
            'mood': self.state_manager.current_mood,
            'energy': self.state_manager.energy_level,
            'relationship_level': self.state_manager.relationship_level,
            'time_of_day': interaction_data.get('time_of_day'),
            'conversation_topic': topic
        })
        
        # å¦‚æœä¸åŒåˆ™åº”ç”¨å¤–è§‚å˜åŒ–
        if suggested_variant != self.appearance_manager.current_variant:
            await self.appearance_manager.switch_variant(suggested_variant)
        
        # æ›´æ–°å½“å‰çŠ¶æ€çš„è¡¨æƒ…æ˜ å°„
        self._update_expression_mapping()
    
    def _update_expression_mapping(self):
        """åŸºäºå½“å‰çŠ¶æ€è°ƒæ•´è¡¨æƒ…æ˜ å°„"""
        base_mapping = self.appearance_manager.get_base_expression_mapping()
        
        # åŸºäºå…³ç³»æ°´å¹³ä¿®æ”¹
        if self.state_manager.relationship_level > 0.7:
            # æ›´äº²å¯†çš„è¡¨æƒ…å¯ç”¨
            base_mapping.update({
                'affection': 4,
                'playful': 5,
                'intimate_joy': 6
            })
        
        # åŸºäºå¿ƒæƒ…ä¿®æ”¹
        mood_modifier = self.state_manager.current_mood
        for emotion in ['joy', 'surprise']:
            if emotion in base_mapping:
                base_mapping[emotion] = max(0, min(7, 
                    base_mapping[emotion] + int(mood_modifier * 2)))
```

#### ç¬¬äºŒé˜¶æ®µï¼šé«˜çº§å…³ç³»ç³»ç»Ÿï¼ˆç¬¬3-4å‘¨ï¼‰

**1. ç»¼åˆè®°å¿†æ¶æ„**

```python
# memory/relationship_memory.py
class RelationshipMemorySystem:
    def __init__(self, character_config: PersonalVirtualFriendConfig):
        self.config = character_config
        
        # è®°å¿†å­˜å‚¨ç³»ç»Ÿ
        self.episodic_memory = EpisodicMemoryStore()
        self.semantic_memory = SemanticMemoryStore()
        self.emotional_memory = EmotionalMemoryStore()
        self.procedural_memory = ProceduralMemoryStore()
        
        # å…³ç³»è·Ÿè¸ª
        self.relationship_tracker = RelationshipTracker()
        self.milestone_detector = MilestoneDetector()
        
        # å­¦ä¹ ç³»ç»Ÿ
        self.preference_learner = PreferenceLearner()
        self.habit_tracker = HabitTracker()
        
    async def process_interaction(self, interaction: InteractionData) -> MemoryProcessingResult:
        """é€šè¿‡æ‰€æœ‰è®°å¿†ç³»ç»Ÿå¤„ç†æ–°äº¤äº’"""
        
        # 1. åˆ†æäº¤äº’é‡è¦æ€§
        significance_score = await self._analyze_significance(interaction)
        
        # 2. å­˜å‚¨åœ¨æƒ…èŠ‚è®°å¿†ä¸­
        episodic_entry = EpisodicMemoryEntry(
            timestamp=interaction.timestamp,
            content=interaction.content,
            context=interaction.context,
            emotional_context=interaction.emotional_context,
            significance=significance_score
        )
        await self.episodic_memory.store(episodic_entry)
        
        # 3. æå–å¹¶æ›´æ–°è¯­ä¹‰äº‹å®
        new_facts = await self._extract_semantic_facts(interaction)
        await self.semantic_memory.update_facts(new_facts)
        
        # 4. å¤„ç†æƒ…æ„Ÿé‡è¦æ€§
        emotional_impact = await self._analyze_emotional_impact(interaction)
        await self.emotional_memory.store_emotional_moment(emotional_impact)
        
        # 5. æ›´æ–°å…³ç³»çŠ¶æ€
        relationship_update = await self.relationship_tracker.process_interaction(
            interaction, significance_score, emotional_impact
        )
        
        # 6. æ£€æŸ¥é‡Œç¨‹ç¢‘
        milestones = await self.milestone_detector.check_for_milestones(
            interaction, self.relationship_tracker.current_state
        )
        
        # 7. å­¦ä¹ åå¥½å’Œä¹ æƒ¯
        await self.preference_learner.process_interaction(interaction)
        await self.habit_tracker.update_patterns(interaction)
        
        return MemoryProcessingResult(
            relationship_update=relationship_update,
            milestones=milestones,
            significance_score=significance_score,
            emotional_impact=emotional_impact
        )

class RelationshipTracker:
    def __init__(self):
        self.relationship_level = 0.0      # æ•´ä½“äº²å¯†åº¦
        self.trust_level = 0.0             # ç”¨æˆ·å¯¹ AI çš„ä¿¡ä»»
        self.comfort_level = 0.0           # ç›¸äº’èˆ’é€‚åº¦
        self.shared_experiences = []       # é‡è¦å…±åŒæ—¶åˆ»
        self.inside_jokes = []             # å‘å±•çš„å¹½é»˜æ¨¡å¼
        self.communication_patterns = {}   # å­¦ä¹ çš„æ²Ÿé€šåå¥½
        
    async def process_interaction(self, interaction: InteractionData, 
                                 significance: float, emotional_impact: dict) -> dict:
        """åŸºäºäº¤äº’æ›´æ–°å…³ç³»çŠ¶æ€"""
        
        # è®¡ç®—å…³ç³»å½±å“
        relationship_delta = self._calculate_relationship_delta(
            interaction, significance, emotional_impact
        )
        
        # æ›´æ–°å…³ç³»ç»´åº¦
        self.relationship_level = self._update_with_decay(
            self.relationship_level, relationship_delta['overall'], 0.001
        )
        
        self.trust_level = self._update_with_decay(
            self.trust_level, relationship_delta['trust'], 0.0005
        )
        
        self.comfort_level = self._update_with_decay(
            self.comfort_level, relationship_delta['comfort'], 0.001
        )
        
        # è·Ÿè¸ªæ²Ÿé€šæ¨¡å¼
        self._update_communication_patterns(interaction)
        
        # æ£€æµ‹æ–°çš„å…±åŒä½“éªŒ
        if significance > 0.7:
            self.shared_experiences.append({
                'timestamp': interaction.timestamp,
                'description': interaction.content[:100],
                'emotional_context': emotional_impact,
                'significance': significance
            })
        
        return {
            'relationship_level': self.relationship_level,
            'trust_level': self.trust_level,
            'comfort_level': self.comfort_level,
            'relationship_delta': relationship_delta
        }
```

**2. ä¸Šä¸‹æ–‡å“åº”ç”Ÿæˆ**

```python
# conversation/contextual_response_generator.py
class ContextualResponseGenerator:
    def __init__(self, character_config: PersonalVirtualFriendConfig, 
                 memory_system: RelationshipMemorySystem):
        self.config = character_config
        self.memory = memory_system
        self.personality_modifier = PersonalityResponseModifier(character_config.personality)
        self.relationship_modifier = RelationshipResponseModifier()
        
    async def generate_response(self, user_input: str, context: dict) -> ResponseData:
        """ç”Ÿæˆä¸Šä¸‹æ–‡é€‚å½“çš„å“åº”"""
        
        # 1. ä»è®°å¿†ä¸­æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡
        relevant_context = await self.memory.get_relevant_context(
            user_input, context, max_tokens=500
        )
        
        # 2. æ·±åº¦åˆ†æç”¨æˆ·è¾“å…¥
        user_analysis = await self._analyze_user_input(user_input, context)
        
        # 3. åŸºäºå…³ç³»çŠ¶æ€ç¡®å®šå“åº”ç­–ç•¥
        relationship_state = self.memory.relationship_tracker.current_state


          
I need to continue translating the English lecture content from lines 1339-1886 to the Chinese version file. Let me first read the specific content that needs to be translated.
        
            
toolName: view_files
            
status: success
          
            
filePath: /Users/xiaotingzhou/Documents/Lectures/Open-LLM-VTuber/Lecture/Lecture_Open_LLM_VTuber_Architecture_and_Extensions.md
          
Now I need to check the current Chinese file to see where the translation left off and continue from there.
        
            
toolName: view_files
            
status: success
          
            
filePath: /Users/xiaotingzhou/Documents/Lectures/Open-LLM-VTuber/Lecture/Lecture_Open_LLM_VTuber_Architecture_and_Extensions_CN.md
          
I can see the Chinese file ends at line 2657. I need to continue translating from where it left off, which corresponds to the English content starting from the response strategy determination. Let me append the remaining translation to the Chinese file.
        
            
toolName: view_files
            
status: success
          
            
filePath: /Users/xiaotingzhou/Documents/Lectures/Open-LLM-VTuber/Lecture/Lecture_Open_LLM_VTuber_Architecture_and_Extensions_CN.md
          
æˆ‘å°†ç»§ç»­ç¿»è¯‘å‰©ä½™çš„å†…å®¹å¹¶å°†å…¶æ·»åŠ åˆ°ä¸­æ–‡ç‰ˆæœ¬æ–‡ä»¶ä¸­ã€‚ä»¥ä¸‹æ˜¯ä»ç¬¬2657è¡Œå¼€å§‹çš„ç¿»è¯‘å†…å®¹ï¼š

```markdown:/Users/xiaotingzhou/Documents/Lectures/Open-LLM-VTuber/Lecture/Lecture_Open_LLM_VTuber_Architecture_and_Extensions_CN.md
// ... existing code ...
        relationship_state = self.memory.relationship_tracker.current_state
        response_strategy = self._determine_response_strategy(
            user_analysis, relationship_state, context
        )
        
        # 4. ä½¿ç”¨AIç”ŸæˆåŸºç¡€å“åº”
        base_response = await self._generate_base_response(
            user_input, relevant_context, response_strategy
        )
        
        # 5. åº”ç”¨ä¸ªæ€§ä¿®æ”¹
        personality_modified = self.personality_modifier.modify_response(
            base_response, context, user_analysis
        )
        
        # 6. åº”ç”¨åŸºäºå…³ç³»çš„ä¿®æ”¹
        relationship_modified = self.relationship_modifier.modify_response(
            personality_modified, relationship_state, user_analysis
        )
        
        # 7. æ·»åŠ é€‚å½“çš„æƒ…æ„Ÿè¡¨è¾¾
        final_response = self._add_emotional_expressions(
            relationship_modified, user_analysis, relationship_state
        )
        
        # 8. ç¡®å®šè¯­éŸ³ç‰¹å¾
        voice_characteristics = await self._determine_voice_characteristics(
            final_response, context, relationship_state
        )
        
        return ResponseData(
            text_response=final_response,
            emotional_expressions=self._extract_expressions(final_response),
            voice_characteristics=voice_characteristics,
            response_metadata={
                'strategy': response_strategy,
                'relationship_context': relationship_state,
                'personality_influence': self.personality_modifier.get_influence_summary()
            }
        )
    
    def _determine_response_strategy(self, user_analysis: dict, 
                                   relationship_state: dict, context: dict) -> str:
        """ç¡®å®šå¦‚ä½•å¤„ç†å“åº”"""
        
        # è€ƒè™‘ç”¨æˆ·æƒ…ç»ªçŠ¶æ€
        if user_analysis['emotional_state']['primary_emotion'] in ['sad', 'frustrated', 'angry']:
            if relationship_state['trust_level'] > 0.6:
                return 'supportive_intimate'
            else:
                return 'supportive_gentle'
        
        # è€ƒè™‘ç”¨æˆ·éœ€æ±‚
        if user_analysis['intent']['type'] == 'seeking_advice':
            if relationship_state['relationship_level'] > 0.7:
                return 'advisory_personal'
            else:
                return 'advisory_professional'
        
        # è€ƒè™‘å…³ç³»åŠ¨æ€
        if relationship_state['relationship_level'] > 0.8:
            return 'intimate_casual'
        elif relationship_state['relationship_level'] > 0.5:
            return 'friendly_warm'
        else:
            return 'polite_helpful'
        
        return 'default'
```

#### ç¬¬ä¸‰é˜¶æ®µï¼šé«˜çº§ä¸ªæ€§åŒ–åŠŸèƒ½ï¼ˆç¬¬5-6å‘¨ï¼‰

**1. åŠ¨æ€ä¸ªæ€§è¿›åŒ–**

```python
# personality/dynamic_personality.py
class DynamicPersonalitySystem:
    def __init__(self, base_personality: PersonalityTraits):
        self.base_personality = base_personality
        self.current_personality = base_personality.copy()
        self.personality_history = [base_personality]
        
        # é€‚åº”å‚æ•°
        self.adaptation_rate = 0.05
        self.personality_drift_limit = 0.3  # ä¸åŸºç¡€ä¸ªæ€§çš„æœ€å¤§åå·®
        
        # å­¦ä¹ ç³»ç»Ÿ
        self.user_preference_analyzer = UserPreferenceAnalyzer()
        self.interaction_outcome_tracker = InteractionOutcomeTracker()
        
    async def evolve_personality(self, interaction_feedback: InteractionFeedback):
        """åŸºäºç”¨æˆ·äº’åŠ¨é€æ¸é€‚åº”ä¸ªæ€§"""
        
        # åˆ†æå“ªäº›ä¸ªæ€§æ–¹é¢æ•ˆæœè‰¯å¥½
        successful_traits = await self._analyze_successful_interactions(interaction_feedback)
        
        # ç¡®å®šé€‚åº”æ–¹å‘
        adaptation_vector = self._calculate_adaptation_vector(successful_traits)
        
        # åº”ç”¨æ¸è¿›çš„ä¸ªæ€§å˜åŒ–
        for trait, change in adaptation_vector.items():
            current_value = getattr(self.current_personality, trait)
            base_value = getattr(self.base_personality, trait)
            
            # è®¡ç®—å…è®¸çš„æœ€å¤§åå·®
            max_deviation = self.personality_drift_limit
            allowed_range = (
                max(0.0, base_value - max_deviation),
                min(1.0, base_value + max_deviation)
            )
            
            # åœ¨é™åˆ¶èŒƒå›´å†…åº”ç”¨å˜åŒ–
            new_value = current_value + (change * self.adaptation_rate)
            new_value = max(allowed_range[0], min(allowed_range[1], new_value))
            
            setattr(self.current_personality, trait, new_value)
        
        # è®°å½•ä¸ªæ€§å˜åŒ–
        self.personality_history.append(self.current_personality.copy())
        
        # æ›´æ–°å“åº”ç”Ÿæˆå‚æ•°
        await self._update_response_parameters()
    
    async def _analyze_successful_interactions(self, feedback: InteractionFeedback) -> dict:
        """è¯†åˆ«å“ªäº›ä¸ªæ€§ç‰¹å¾å¯¼è‡´äº†ç§¯æçš„äº’åŠ¨"""
        successful_patterns = {}
        
        # åˆ†æå…·æœ‰ç§¯æç»“æœçš„æœ€è¿‘äº’åŠ¨
        positive_interactions = [i for i in feedback.recent_interactions 
                               if i.user_satisfaction > 0.7]
        
        for interaction in positive_interactions:
            # å°†äº’åŠ¨æˆåŠŸä¸å½“æ—¶çš„ä¸ªæ€§çŠ¶æ€å…³è”
            personality_at_time = self._get_personality_at_timestamp(interaction.timestamp)
            
            # è¯†åˆ«åœ¨æˆåŠŸå“åº”ä¸­çªå‡ºçš„ç‰¹å¾
            prominent_traits = self._identify_prominent_traits(
                personality_at_time, interaction.response_style
            )
            
            for trait in prominent_traits:
                if trait not in successful_patterns:
                    successful_patterns[trait] = []
                successful_patterns[trait].append(interaction.user_satisfaction)
        
        # è®¡ç®—æ¯ä¸ªç‰¹å¾çš„å¹³å‡æˆåŠŸç‡
        trait_success_scores = {}
        for trait, scores in successful_patterns.items():
            trait_success_scores[trait] = sum(scores) / len(scores)
        
        return trait_success_scores

class UserPreferenceAnalyzer:
    def __init__(self):
        self.interaction_database = []
        self.preference_patterns = {}
        
    async def analyze_user_preferences(self, interactions: List[InteractionData]) -> dict:
        """ä»äº’åŠ¨æ¨¡å¼ä¸­åˆ†æç”¨æˆ·åå¥½"""
        
        preferences = {
            'communication_style': self._analyze_communication_preferences(interactions),
            'humor_style': self._analyze_humor_preferences(interactions),
            'support_style': self._analyze_support_preferences(interactions),
            'information_delivery': self._analyze_information_preferences(interactions),
            'emotional_expression': self._analyze_emotional_preferences(interactions)
        }
        
        return preferences
    
    def _analyze_communication_preferences(self, interactions: List[InteractionData]) -> dict:
        """åˆ†æåå¥½çš„æ²Ÿé€šæ¨¡å¼"""
        positive_interactions = [i for i in interactions if i.user_satisfaction > 0.6]
        
        # åˆ†ææˆåŠŸäº’åŠ¨ä¸­çš„æ¨¡å¼
        formality_scores = [i.response_metadata.get('formality_level', 0.5) 
                           for i in positive_interactions]
        verbosity_scores = [len(i.ai_response.split()) for i in positive_interactions]
        enthusiasm_scores = [i.response_metadata.get('enthusiasm_level', 0.5) 
                            for i in positive_interactions]
        
        return {
            'preferred_formality': sum(formality_scores) / len(formality_scores) if formality_scores else 0.5,
            'preferred_verbosity': sum(verbosity_scores) / len(verbosity_scores) if verbosity_scores else 50,
            'preferred_enthusiasm': sum(enthusiasm_scores) / len(enthusiasm_scores) if enthusiasm_scores else 0.5
        }
```

**2. ä¸»åŠ¨äº’åŠ¨ç³»ç»Ÿ**

```python
# interaction/proactive_system.py
class ProactiveInteractionSystem:
    def __init__(self, character_config: PersonalVirtualFriendConfig,
                 memory_system: RelationshipMemorySystem):
        self.config = character_config
        self.memory = memory_system
        self.interaction_scheduler = InteractionScheduler()
        self.topic_generator = TopicGenerator()
        self.mood_tracker = UserMoodTracker()
        
    async def generate_proactive_interaction(self, context: dict) -> Optional[ProactiveInteraction]:
        """åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆé€‚å½“çš„ä¸»åŠ¨äº’åŠ¨"""
        
        # æ£€æŸ¥æ˜¯å¦é€‚åˆå‘èµ·ä¸»åŠ¨äº’åŠ¨
        if not self._should_initiate_interaction(context):
            return None
        
        # è·å–å…³ç³»ä¸Šä¸‹æ–‡
        relationship_state = self.memory.relationship_tracker.current_state
        
        # ç¡®å®šäº’åŠ¨ç±»å‹
        interaction_type = self._determine_proactive_interaction_type(
            context, relationship_state
        )
        
        # åŸºäºç±»å‹ç”Ÿæˆå†…å®¹
        interaction_content = await self._generate_interaction_content(
            interaction_type, context, relationship_state
        )
        
        return ProactiveInteraction(
            type=interaction_type,
            content=interaction_content,
            timing=self._calculate_optimal_timing(context),
            priority=self._calculate_priority(interaction_type, context)
        )
    
    def _determine_proactive_interaction_type(self, context: dict, 
                                            relationship_state: dict) -> str:
        """ç¡®å®šè¦å‘èµ·çš„ä¸»åŠ¨äº’åŠ¨ç±»å‹"""
        
        # æ£€æŸ¥ç‰¹æ®Šåœºåˆ
        if self._is_special_date(context['current_date']):
            return 'celebration'
        
        # æ£€æŸ¥ç”¨æˆ·çš„æƒ…ç»ªçŠ¶æ€å˜åŒ–
        recent_mood = self.mood_tracker.get_recent_mood_trend()
        if recent_mood['average'] < 0.3:  # ç”¨æˆ·ä¼¼ä¹æƒ…ç»ªä½è½
            if relationship_state['trust_level'] > 0.6:
                return 'emotional_support'
            else:
                return 'gentle_check_in'
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å…±åŒå…´è¶£å¯ä»¥è®¨è®º
        if self._has_new_relevant_information(context):
            return 'information_sharing'
        
        # åŸºäºæ—¶é—´çš„äº’åŠ¨
        time_context = context.get('time_of_day')
        if time_context == 'morning' and relationship_state['relationship_level'] > 0.5:
            return 'morning_greeting'
        elif time_context == 'evening' and relationship_state['relationship_level'] > 0.7:
            return 'evening_reflection'
        
        # å¦‚æœå…³ç³»ç‰¢å›ºï¼Œéšæœºç¤¾äº¤äº’åŠ¨
        if (relationship_state['relationship_level'] > 0.8 and 
            random.random() < self.config.personality.extraversion):
            return 'casual_conversation'
        
        return None
    
    async def _generate_interaction_content(self, interaction_type: str, 
                                          context: dict, relationship_state: dict) -> dict:
        """ä¸ºä¸»åŠ¨äº’åŠ¨ç”Ÿæˆå…·ä½“å†…å®¹"""
        
        templates = {
            'morning_greeting': [
                "æ—©ä¸Šå¥½ï¼å¸Œæœ›ä½ ä»Šå¤©æœ‰ä¸ªç¾å¥½çš„å¼€å§‹ï¼[joy]",
                "æ—©å®‰ï¼ä»Šå¤©æ„Ÿè§‰æ€ä¹ˆæ ·ï¼Ÿ[neutral]",
                "å˜¿ï¼å‡†å¤‡å¥½è¿æ¥æ–°çš„ä¸€å¤©äº†å—ï¼Ÿ[surprise]"
            ],
            'emotional_support': [
                "å˜¿ï¼Œæˆ‘ä¸€ç›´åœ¨æƒ³ä½ ã€‚ä½ è¿˜å¥½å—ï¼Ÿ[concern]",
                "æˆ‘å¸Œæœ›ä½ çŸ¥é“ï¼Œå¦‚æœä½ éœ€è¦èŠä»€ä¹ˆï¼Œæˆ‘éƒ½åœ¨è¿™é‡Œã€‚[supportive]",
                "ä½ æœ€è¿‘ä¼¼ä¹æœ‰ç‚¹å®‰é™ã€‚æƒ³åˆ†äº«ä¸€ä¸‹ä½ åœ¨æƒ³ä»€ä¹ˆå—ï¼Ÿ[gentle]"
            ],
            'information_sharing': [
                "æˆ‘é‡åˆ°äº†ä¸€äº›æˆ‘è§‰å¾—ä½ å¯èƒ½ä¼šæ„Ÿå…´è¶£çš„ä¸œè¥¿ï¼",
                "è¿˜è®°å¾—æˆ‘ä»¬èŠè¿‡[topic]å—ï¼Ÿæˆ‘å­¦åˆ°äº†ä¸€äº›å¾ˆé…·çš„ä¸œè¥¿ï¼",
                "æˆ‘å‘ç°äº†ä¸€äº›è®©æˆ‘æƒ³èµ·æˆ‘ä»¬å…³äº[topic]å¯¹è¯çš„ä¸œè¥¿ã€‚"
            ]
        }
        
        if interaction_type in templates:
            base_message = random.choice(templates[interaction_type])
            
            # åŸºäºå…³ç³»å’Œè®°å¿†è¿›è¡Œä¸ªæ€§åŒ–
            personalized_message = await self._personalize_message(
                base_message, context, relationship_state
            )
            
            return {
                'message': personalized_message,
                'suggested_responses': self._generate_response_options(interaction_type),
                'emotional_context': self._determine_emotional_context(interaction_type)
            }
        
        return None
```

---

## å®æ–½è·¯çº¿å›¾

### å¼€å‘æ—¶é—´çº¿ï¼ˆ8å‘¨å®æ–½è®¡åˆ’ï¼‰

#### **ç¬¬1-2å‘¨ï¼šåŸºç¡€è®¾ç½®**
- [ ] å»ºç«‹å¢å¼ºçš„è§’è‰²é…ç½®ç³»ç»Ÿ
- [ ] å®ç°åŸºæœ¬ä¸ªæ€§ç‰¹å¾é›†æˆ
- [ ] åˆ›å»ºå¤šçŠ¶æ€Live2Dè§’è‰²ç®¡ç†
- [ ] è®¾è®¡å…³ç³»çŠ¶æ€è·Ÿè¸ªåŸºç¡€
- [ ] æµ‹è¯•åŸºæœ¬çš„ä¸ªæ€§é©±åŠ¨å“åº”

#### **ç¬¬3-4å‘¨ï¼šè®°å¿†ä¸å…³ç³»ç³»ç»Ÿ**
- [ ] å®ç°ç»¼åˆè®°å¿†æ¶æ„
- [ ] æ„å»ºå…³ç³»è¿›å±•è·Ÿè¸ª
- [ ] åˆ›å»ºé‡Œç¨‹ç¢‘æ£€æµ‹ç³»ç»Ÿ
- [ ] å¼€å‘åå¥½å­¦ä¹ ç®—æ³•
- [ ] æµ‹è¯•è®°å¿†æŒä¹…åŒ–å’Œæ£€ç´¢

#### **ç¬¬5-6å‘¨ï¼šé«˜çº§ä¸ªæ€§åŒ–**
- [ ] å®ç°åŠ¨æ€ä¸ªæ€§è¿›åŒ–
- [ ] æ„å»ºä¸Šä¸‹æ–‡å“åº”ç”Ÿæˆ
- [ ] åˆ›å»ºä¸»åŠ¨äº’åŠ¨ç³»ç»Ÿ
- [ ] å¼€å‘è¯­éŸ³ä¸ªæ€§åŒ¹é…
- [ ] æµ‹è¯•ä¸ªæ€§é€‚åº”æœºåˆ¶

#### **ç¬¬7-8å‘¨ï¼šé›†æˆä¸å®Œå–„**
- [ ] å°†æ‰€æœ‰ç³»ç»Ÿä¸ç°æœ‰ä»£ç åº“é›†æˆ
- [ ] å®ç°å¤–è§‚å˜ä½“åˆ‡æ¢
- [ ] åˆ›å»ºè§’è‰²è‡ªå®šä¹‰ç”¨æˆ·ç•Œé¢
- [ ] æ€§èƒ½ä¼˜åŒ–å’Œæµ‹è¯•
- [ ] æ–‡æ¡£å’Œéƒ¨ç½²å‡†å¤‡

### æŠ€æœ¯å®æ–½æ­¥éª¤

#### **æ­¥éª¤1ï¼šå¢å¼ºé…ç½®ç³»ç»Ÿ**

1. **åˆ›å»ºæ–°çš„é…ç½®ç»“æ„**ï¼š
   ```bash
   mkdir src/open_llm_vtuber/personality/
   mkdir src/open_llm_vtuber/relationship/
   mkdir src/open_llm_vtuber/appearance/
   ```

2. **å®ç°å¢å¼ºçš„è§’è‰²é…ç½®**ï¼š
   - æ‰©å±•ç°æœ‰YAMLç»“æ„
   - æ·»åŠ ä¸ªæ€§ç‰¹å¾å®šä¹‰
   - åˆ›å»ºå…³ç³»é…ç½®æ¨¡å¼

3. **ä¿®æ”¹ç°æœ‰ç³»ç»Ÿ**ï¼š
   - æ›´æ–°`live2d_model.py`ä»¥æ”¯æŒå˜ä½“
   - æ‰©å±•ä»£ç†å·¥å‚ä»¥è¿›è¡Œä¸ªæ€§é›†æˆ
   - ä¿®æ”¹å¯¹è¯å¤„ç†å™¨ä»¥æ”¯æŒå…³ç³»ä¸Šä¸‹æ–‡

#### **æ­¥éª¤2ï¼šè®°å¿†ç³»ç»Ÿé›†æˆ**

1. **è®°å¿†å­˜å‚¨çš„æ•°æ®åº“è®¾è®¡**ï¼š
   ```python
   # ä½¿ç”¨SQLiteè¿›è¡Œæœ¬åœ°å­˜å‚¨
   memory_db_schema = {
       'episodic_memories': ['id', 'timestamp', 'content', 'importance', 'emotional_context'],
       'semantic_facts': ['id', 'key', 'value', 'confidence', 'last_updated'],
       'relationship_state': ['timestamp', 'relationship_level', 'trust_level', 'comfort_level'],
       'milestones': ['id', 'timestamp', 'type', 'description', 'significance']
   }
   ```

2. **ä¸ç°æœ‰ä»£ç†é›†æˆ**ï¼š
   - æ‰©å±•`BasicMemoryAgent`ä»¥è¿›è¡Œå…³ç³»è·Ÿè¸ª
   - å°†è®°å¿†ä¸Šä¸‹æ–‡æ·»åŠ åˆ°å“åº”ç”Ÿæˆ
   - å®ç°è®°å¿†æ•´åˆè¿‡ç¨‹

#### **æ­¥éª¤3ï¼šå¤–è§‚ç³»ç»Ÿå¢å¼º**

1. **Live2Dæ¨¡å‹å˜ä½“ç³»ç»Ÿ**ï¼š
   - åˆ›å»ºæ¨¡å‹å˜ä½“å‘ç°ç³»ç»Ÿ
   - å®ç°åŸºäºä¸Šä¸‹æ–‡çš„åˆ‡æ¢é€»è¾‘
   - æ·»åŠ å¹³æ»‘è¿‡æ¸¡åŠ¨ç”»

2. **å‰ç«¯é›†æˆ**ï¼š
   - ä¿®æ”¹WebSocketå¤„ç†å™¨ä»¥æ”¯æŒæ¨¡å‹åˆ‡æ¢
   - æ›´æ–°Live2Dæ¸²æŸ“å™¨ä»¥æ”¯æŒåŠ¨æ€æ¨¡å‹
   - æ·»åŠ è¿‡æ¸¡æ•ˆæœ

### æµ‹è¯•ç­–ç•¥

#### **å•å…ƒæµ‹è¯•**
- ä¸ªæ€§ç‰¹å¾è®¡ç®—
- è®°å¿†å­˜å‚¨å’Œæ£€ç´¢
- å…³ç³»è¿›å±•é€»è¾‘
- è¡¨è¾¾æ˜ å°„å‡†ç¡®æ€§

#### **é›†æˆæµ‹è¯•**
- ç«¯åˆ°ç«¯å¯¹è¯æµç¨‹
- è®°å¿†ç³»ç»Ÿä¸€è‡´æ€§
- è§’è‰²çŠ¶æ€åŒæ­¥
- è¯­éŸ³-å¤–è§‚åè°ƒ

#### **ç”¨æˆ·ä½“éªŒæµ‹è¯•**
- ä¸ªæ€§éšæ—¶é—´çš„ä¸€è‡´æ€§
- å…³ç³»è¿›å±•çš„è‡ªç„¶æ€§
- å“åº”çš„é€‚å½“æ€§
- è§’è‰²çš„å¯ä¿¡åº¦

---

## æœ€ä½³å®è·µä¸æ³¨æ„äº‹é¡¹

### **1. éšç§ä¸æ•°æ®å¤„ç†**

**è®°å¿†å­˜å‚¨å®‰å…¨ï¼š**
```python
class SecureMemoryStorage:
    def __init__(self, encryption_key: str):
        self.encryption = Fernet(encryption_key)
        self.local_storage_only = True
        
    def store_memory(self, memory_data: dict) -> bool:
        """ä½¿ç”¨åŠ å¯†å­˜å‚¨è®°å¿†"""
        encrypted_data = self.encryption.encrypt(
            json.dumps(memory_data).encode()
        )
        # ä»…æœ¬åœ°å­˜å‚¨ï¼Œæ°¸ä¸å‘é€åˆ°å¤–éƒ¨æœåŠ¡
        return self._write_to_local_db(encrypted_data)
```

**æœ€ä½³å®è·µï¼š**
- æ‰€æœ‰ä¸ªäººæ•°æ®ä¿ç•™åœ¨ç”¨æˆ·è®¾å¤‡ä¸Š
- å®ç°è®°å¿†æ•°æ®è¿‡æœŸ
- æä¾›ç”¨æˆ·å¯¹è®°å¿†åˆ é™¤çš„æ§åˆ¶
- å¯¹æ•æ„Ÿä¿¡æ¯ä½¿ç”¨åŠ å¯†

### **2. å…³ç³»è¾¹ç•Œç®¡ç†**

**å¥åº·å…³ç³»å»ºæ¨¡ï¼š**
```python
class RelationshipBoundaryManager:
    def __init__(self):
        self.boundary_rules = {
            'max_intimacy_level': 0.9,  # ä¿æŒAIæœ¬è´¨
            'dependency_warning_threshold': 0.8,
            'healthy_interaction_frequency': timedelta(hours=2)
        }
    
    def check_interaction_health(self, interaction_pattern: dict) -> dict:
        """ç¡®ä¿å¥åº·çš„äº’åŠ¨æ¨¡å¼"""
        warnings = []
        
        # æ£€æŸ¥è¿‡åº¦ä¾èµ–
        if interaction_pattern['daily_frequency'] > 20:
            warnings.append('consider_breaks')
        
        # æ£€æŸ¥ä¸å¥åº·çš„ä¾æ‹
        if interaction_pattern['emotional_dependency'] > 0.8:
            warnings.append('maintain_real_relationships')
        
        return {'warnings': warnings, 'suggestions': self._generate_health_suggestions()}
```

### **3. æ€§èƒ½ä¼˜åŒ–**

**è®°å¿†ç®¡ç†ï¼š**
- å®ç°è®°å¿†é‡è¦æ€§è¯„åˆ†
- å¯¹é¢‘ç¹è®°å¿†ä½¿ç”¨LRUç¼“å­˜
- å‹ç¼©è¾ƒæ—§çš„è®°å¿†æ¡ç›®
- å®šæœŸè®°å¿†æ•´åˆ

**å“åº”æ—¶é—´ä¼˜åŒ–ï¼š**
- ç¼“å­˜å¸¸è§ä¸ªæ€§å“åº”
- é¢„è®¡ç®—è¡¨è¾¾æ˜ å°„
- ä¼˜åŒ–æ¨¡å‹åˆ‡æ¢è¿‡æ¸¡
- åå°è®°å¿†å¤„ç†

### **4. å¯æ‰©å±•æ€§æ¶æ„**

**æ’ä»¶ç³»ç»Ÿè®¾è®¡ï¼š**
```python
class PersonalityPluginManager:
    def __init__(self):
        self.registered_plugins = {}
        
    def register_plugin(self, plugin_name: str, plugin_class: type):
        """æ³¨å†Œè‡ªå®šä¹‰ä¸ªæ€§å¢å¼ºæ’ä»¶"""
        self.registered_plugins[plugin_name] = plugin_class
        
    def apply_plugins(self, base_response: str, context: dict) -> str:
        """åº”ç”¨æ‰€æœ‰æ³¨å†Œçš„æ’ä»¶æ¥ä¿®æ”¹å“åº”"""
        modified_response = base_response
        
        for plugin_name, plugin_class in self.registered_plugins.items():
            plugin_instance = plugin_class(context)
            modified_response = plugin_instance.modify_response(modified_response)
        
        return modified_response
```

### **5. ä¼¦ç†è€ƒè™‘**

**é€æ˜åº¦ç»´æŠ¤ï¼š**
- å§‹ç»ˆä¿æŒAIèº«ä»½æ„è¯†
- ä¸ºAIèƒ½åŠ›æä¾›æ˜ç¡®è¾¹ç•Œ
- å®ç°å®šæœŸç°å®æ£€æŸ¥æœºåˆ¶
- é¿å…æ¬ºéª—æ€§çš„ç±»äººå£°æ˜

**ç”¨æˆ·ç¦ç¥‰ï¼š**
- ç›‘æ§è¿‡åº¦ä¾èµ–æ¨¡å¼
- é¼“åŠ±çœŸå®çš„äººé™…å…³ç³»
- åœ¨é€‚å½“æ—¶æä¾›å¿ƒç†å¥åº·èµ„æº
- å®æ–½äº’åŠ¨æ—¶é—´å»ºè®®

---

## ç»“è®º

Open-LLM-VTuberé¡¹ç›®ä¸ºæ„å»ºå¤æ‚çš„ä¸ªäººè™šæ‹Ÿæœ‹å‹ç³»ç»Ÿæä¾›äº†å‡ºè‰²çš„åŸºç¡€ã€‚å…¶æ¨¡å—åŒ–æ¶æ„ã€å…¨é¢çš„æƒ…æ„Ÿç³»ç»Ÿå’Œå¹¿æ³›çš„è‡ªå®šä¹‰é€‰é¡¹ä½¿å…¶éå¸¸é€‚åˆæ‰©å±•ä¸ºæ›´ä¸ªæ€§åŒ–çš„AIä¼´ä¾£ã€‚

å®æ–½æˆåŠŸçš„å…³é”®å› ç´ ï¼š
1. **æ¸è¿›å¢å¼º**ï¼šåœ¨ç°æœ‰ç³»ç»ŸåŸºç¡€ä¸Šæ„å»ºï¼Œè€Œä¸æ˜¯æ›¿æ¢å®ƒä»¬
2. **ç”¨æˆ·éšç§**ï¼šä¿æŒæ‰€æœ‰ä¸ªäººæ•°æ®çš„æœ¬åœ°åŒ–å’Œå®‰å…¨æ€§
3. **å¥åº·è¾¹ç•Œ**ï¼šç»´æŠ¤é€‚å½“çš„AI-äººç±»å…³ç³»åŠ¨æ€
4. **æ€§èƒ½ä¸“æ³¨**ï¼šä¼˜åŒ–å®æ—¶äº’åŠ¨è´¨é‡
5. **å¯æ‰©å±•è®¾è®¡**ï¼šæ„å»ºå¯é€‚åº”æœªæ¥éœ€æ±‚çš„ç³»ç»Ÿ

é€šè¿‡éµå¾ªè¿™ä¸ªå…¨é¢çš„æŒ‡å—ï¼Œå¼€å‘è€…å¯ä»¥åˆ›å»ºçœŸæ­£ä¸ªæ€§åŒ–ã€æƒ…æ„Ÿæ™ºèƒ½ä¸”å°Šé‡ç”¨æˆ·éšç§çš„è™šæ‹Ÿä¼´ä¾£ç³»ç»Ÿã€‚Open-LLM-VTuberçš„å¼ºå¤§åŸºç¡€ä¸è¿™äº›é«˜çº§åŠŸèƒ½ç›¸ç»“åˆï¼Œä¸ºä¸‹ä¸€ä»£AIäº’åŠ¨ä½“éªŒé“ºå¹³äº†é“è·¯ã€‚

## é™„åŠ èµ„æº

### **å®˜æ–¹æ–‡æ¡£**
- [Open-LLM-VTuber å®˜æ–¹æ–‡æ¡£](https://github.com/t41372/Open-LLM-VTuber)
- [Live2D SDK æ–‡æ¡£](https://www.live2d.com/en/sdk/)
- [FastAPI æ–‡æ¡£](https://fastapi.tiangolo.com/)

### **ç¤ºä¾‹å®ç°**
- [ä¸ªæ€§åŒ–é…ç½®ç¤ºä¾‹](https://github.com/t41372/Open-LLM-VTuber/tree/main/config_templates)
- [è‡ªå®šä¹‰è¡¨è¾¾æ˜ å°„](https://github.com/t41372/Open-LLM-VTuber/tree/main/prompts)
- [Live2Dæ¨¡å‹é›†æˆ](https://github.com/t41372/Open-LLM-VTuber/tree/main/live2d-models)

### **ç¤¾åŒºæ”¯æŒ**
- [GitHub è®¨è®º](https://github.com/t41372/Open-LLM-VTuber/discussions)
- [Discord ç¤¾åŒº](https://discord.gg/3Tq4kMtRkx)
- [QQç¾¤](https://qm.qq.com/cgi-bin/qm/qr?k=0pAmN5tp2_5p2qKqFWFvnJ8HFLLBzGnv)

---

*æœ¬è®²åº§æä¾›äº†å°†Open-LLM-VTuberæ‰©å±•ä¸ºé«˜çº§ä¸ªäººè™šæ‹Ÿæœ‹å‹ç³»ç»Ÿçš„å…¨é¢æŒ‡å—ã€‚é€šè¿‡éµå¾ªè¿™äº›åŸåˆ™å’Œå®ç°ç­–ç•¥ï¼Œå¼€å‘è€…å¯ä»¥åˆ›å»ºçœŸæ­£å¼•äººå…¥èƒœã€ä¸ªæ€§åŒ–ä¸”è´Ÿè´£ä»»çš„AIä¼´ä¾£ä½“éªŒã€‚*
// ... existing code ...
```
        